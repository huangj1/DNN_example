{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def decode_idx3_ubyte(idx3_ubyte_file):\n",
    "    with open(idx3_ubyte_file, 'rb') as f:\n",
    "        print('解析文件：', idx3_ubyte_file)\n",
    "        fb_data = f.read()\n",
    "\n",
    "    offset = 0\n",
    "    fmt_header = '>iiii'    # 以大端法读取4个 unsinged int32\n",
    "    magic_number, num_images, num_rows, num_cols = struct.unpack_from(fmt_header, fb_data, offset)\n",
    "    print('魔数：{}，图片数：{}'.format(magic_number, num_images))\n",
    "    offset += struct.calcsize(fmt_header)  # 索引跟随\n",
    "    fmt_image = '>' + str(num_rows * num_cols) + 'B'\n",
    "\n",
    "    images = np.empty((num_images, num_rows, num_cols))\n",
    "    for i in range(num_images):\n",
    "        im = struct.unpack_from(fmt_image, fb_data, offset)\n",
    "        images[i] = np.array(im).reshape((num_rows, num_cols))\n",
    "        offset += struct.calcsize(fmt_image)\n",
    "    return images\n",
    "\n",
    "def decode_idx1_ubyte(idx1_ubyte_file):\n",
    "    with open(idx1_ubyte_file, 'rb') as f:\n",
    "        print('解析文件：', idx1_ubyte_file)\n",
    "        fb_data = f.read()\n",
    "\n",
    "    offset = 0\n",
    "    fmt_header = '>ii'  # 以大端法读取两个 unsinged int32\n",
    "    magic_number, label_num = struct.unpack_from(fmt_header, fb_data, offset)\n",
    "    print('魔数：{}，标签数：{}'.format(magic_number, label_num))\n",
    "    offset += struct.calcsize(fmt_header)\n",
    "    labels = []\n",
    "\n",
    "    fmt_label = '>B'    # 每次读取一个 byte\n",
    "    for i in range(label_num):\n",
    "        labels.append(struct.unpack_from(fmt_label, fb_data, offset)[0])\n",
    "        offset += struct.calcsize(fmt_label)\n",
    "    return labels\n",
    "\n",
    "def check_folder(folder):\n",
    "    \"\"\"检查文件文件夹是否存在，不存在则创建\"\"\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "        print(folder)\n",
    "    else:\n",
    "        if not os.path.isdir(folder):\n",
    "            os.mkdir(folder)\n",
    "            print(folder)\n",
    "\n",
    "\n",
    "def export_img(exp_dir, img_ubyte, lable_ubyte):\n",
    "    \"\"\"\n",
    "    生成数据集\n",
    "    \"\"\"\n",
    "    check_folder(exp_dir)\n",
    "    images = decode_idx3_ubyte(img_ubyte)\n",
    "    labels = decode_idx1_ubyte(lable_ubyte)\n",
    "\n",
    "    nums = len(labels)\n",
    "    for i in range(nums):\n",
    "        img_dir = os.path.join(exp_dir, str(labels[i]))\n",
    "        check_folder(img_dir)\n",
    "        img_file = os.path.join(img_dir, str(i)+'.png')\n",
    "        imarr = images[i]\n",
    "        cv2.imwrite(img_file, imarr)\n",
    "\n",
    "\n",
    "def parser_mnist_data(data_dir):\n",
    "\n",
    "    train_dir = os.path.join(data_dir, 'train')\n",
    "    train_img_ubyte = os.path.join(data_dir, 'train-images.idx3-ubyte')\n",
    "    train_label_ubyte = os.path.join(data_dir, 'train-labels.idx1-ubyte')\n",
    "    export_img(train_dir, train_img_ubyte, train_label_ubyte)\n",
    "\n",
    "    test_dir = os.path.join(data_dir, 'test')\n",
    "    test_img_ubyte = os.path.join(data_dir, 't10k-images.idx3-ubyte')\n",
    "    test_label_ubyte = os.path.join(data_dir, 't10k-labels.idx1-ubyte')\n",
    "    export_img(test_dir, test_img_ubyte, test_label_ubyte)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     data_dir = 'G:/MNIST_data/'\n",
    "#     parser_mnist_data(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将原始图片转换成需要的大小，并将其保存位tfrecords格式\n",
    "#========================================================================================\n",
    "import os  \n",
    "import tensorflow as tf  \n",
    "from PIL import Image  \n",
    "import random\n",
    "  \n",
    "# #原始图片的存储位置\n",
    "# orig_picture = 'G:/MNIST_data/train/'\n",
    "\n",
    "# #生成图片的存储位置\n",
    "# gen_picture = 'G:/MNIST_data/'#E:/Re_train/image_data/inputdata/'\n",
    "\n",
    " \n",
    "#需要的识别类型\n",
    "classes = ['0','1','2','3','4','5','6','7','8','9']\n",
    "# for index, name in enumerate(classes):\n",
    "#         print(index,'--',name)\n",
    "\n",
    "def create_txt(img_path):\n",
    "    paths = []\n",
    "    f = open(img_path+'/img.txt', 'w')\n",
    "    for file_name in os.listdir(img_path):\n",
    "        if os.path.isdir(img_path+file_name):\n",
    "            for img_name in os.listdir(img_path+file_name):\n",
    "#                 path = os.path.join(img_path, file_name, img_name)\n",
    "                path = img_path+'/'+file_name+'/'+img_name+' '+file_name\n",
    "                paths.append(path)\n",
    "    random.shuffle(paths)\n",
    "    for i in paths:\n",
    "        f.write(i+'\\n')\n",
    "    f.close()\n",
    "    \n",
    "# create_txt('G:/MNIST_data/train/')\n",
    "def create_record1(tf_path):  \n",
    "    writer = tf.python_io.TFRecordWriter(tf_path)\n",
    "    num_m = 0\n",
    "    f = open('G:/MNIST_data/train/img.txt', 'r')\n",
    "    contents = f.readlines()\n",
    "    f.close()\n",
    "    for content in contents:\n",
    "#         print(content)\n",
    "        image = content.split()\n",
    "#         print(image)\n",
    "        for index, name in enumerate(classes):\n",
    "#             class_path = img_path + name+\"/\"  #每一个分类的图片路径\"G:/MNIST_data/train/0/\n",
    "#             print(image[1],'--',name)\n",
    "            if image[1] == name:\n",
    "                print('读取标签',index,'--',name,image[0])\n",
    "#             for img_name in os.listdir(class_path):  #遍历路径下的文件\n",
    "#                 imgs_path = class_path + img_name  #图片完整路径如\"G:/MNIST_data/train/0/1.png\"\n",
    "#             print('图片';imgs_path)\n",
    "#             print(index,'--',class_path)\n",
    "                img = Image.open(image[0])  # \n",
    "#             img = cv2.imread(imgs_path, cv2.IMREAD_GRAYSCALE)\n",
    "#             img = img.resize((28, 28))    #设置需要转换的图片大小\n",
    "                img_raw = img.tobytes()      #将图片转化 img.tostring()\n",
    "#             img_raw = img.tostring()\n",
    "#             print(index,img_raw)\n",
    "                example = tf.train.Example(  \n",
    "                   features=tf.train.Features(feature={  \n",
    "                        \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[index])),  \n",
    "                        'image_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw]))  \n",
    "                   }))  \n",
    "                writer.write(example.SerializeToString())\n",
    "                num_m +=1\n",
    "    writer.close()\n",
    "    print('the numbers of picture:', num_m)\n",
    "    print(tf_path)\n",
    "# create_record1('G:/MNIST_data/train/train.tfrecords')\n",
    "   \n",
    "# 制作TFRecords数据\n",
    "def create_record(tf_path, img_path):  \n",
    "    writer = tf.python_io.TFRecordWriter(tf_path)\n",
    "    num_m = 0\n",
    "    for index, name in enumerate(classes):\n",
    "        class_path = img_path + name+\"/\"  #每一个分类的图片路径\"G:/MNIST_data/train/0/\n",
    "        print('读取',index,'--',name,class_path)\n",
    "        for img_name in os.listdir(class_path):  #遍历路径下的文件\n",
    "            imgs_path = class_path + img_name  #图片完整路径如\"G:/MNIST_data/train/0/1.png\"\n",
    "#             print('图片';imgs_path)\n",
    "#             print(index,'--',class_path)\n",
    "            img = Image.open(imgs_path)  # \n",
    "#             img = cv2.imread(imgs_path, cv2.IMREAD_GRAYSCALE)\n",
    "#             img = img.resize((28, 28))    #设置需要转换的图片大小\n",
    "            img_raw = img.tobytes()      #将图片转化 img.tostring()\n",
    "#             img_raw = img.tostring()\n",
    "#             print(index,img_raw)\n",
    "            example = tf.train.Example(  \n",
    "               features=tf.train.Features(feature={  \n",
    "                    \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[index])),  \n",
    "                    'image_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw]))  \n",
    "               }))  \n",
    "            writer.write(example.SerializeToString())\n",
    "            num_m +=1\n",
    "    writer.close()\n",
    "    print('the numbers of picture:', num_m)\n",
    "    print(tf_path)\n",
    "\n",
    "tr_tf_path, tr_img_path = 'G:/MNIST_data/train/mnist_train.tfrecords', 'G:/MNIST_data/train/'\n",
    "te_tf_path, te_img_path = 'G:/MNIST_data/test/mnist_test.tfrecords', 'G:/MNIST_data/test/'\n",
    "# create_record(tr_tf_path, tr_img_path)\n",
    "# create_record(te_tf_path, te_img_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#读取frecords并还原为图片\n",
    "#=======================================================================================\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def read_and_decode(filename):  \n",
    "    # 创建文件队列,不限读取的数量  \n",
    "    filename_queue = tf.train.string_input_producer([filename])  \n",
    "    # create a reader from file queue  \n",
    "    reader = tf.TFRecordReader()  \n",
    "    # reader从文件队列中读入一个序列化的样本  \n",
    "    _, serialized_example = reader.read(filename_queue)  \n",
    "    # get feature from serialized example  \n",
    "    # 解析符号化的样本  \n",
    "    features = tf.parse_single_example(  #按原保存的格式解析\n",
    "        serialized_example,  \n",
    "        features={  \n",
    "            'label': tf.FixedLenFeature([], tf.int64),  \n",
    "            'image_raw': tf.FixedLenFeature([], tf.string)  \n",
    "        })  \n",
    "    label = features['label']  \n",
    "    img = features['image_raw']  \n",
    "    de_img = tf.decode_raw(img, tf.uint8) #图像解析为对应的像素数组\n",
    "    \n",
    "    image = tf.reshape(de_img, [28, 28]) #   \n",
    "    labels = tf.cast(label, tf.int32)  \n",
    "    return image, labels \n",
    "\n",
    "def get_tf(batch_size, Train=True):\n",
    "    if Train:\n",
    "        tf_path = tr_tf_path\n",
    "    else:\n",
    "        tf_path = te_tf_path\n",
    "    img, label = read_and_decode(tf_path)\n",
    "    img_batch, label_batch = tf.train.shuffle_batch([img,label],\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   num_threads=2,\n",
    "                                                   capacity=1000,\n",
    "                                                   min_after_dequeue=700)\n",
    "    return img_batch, label_batch\n",
    "\n",
    "#=======================================================================================\n",
    "if __name__ == '__main__':\n",
    "    #样本总数\n",
    "    num_samples = 60000\n",
    "    num_samples_ = 10000\n",
    "    #文件\n",
    "#     filename = \"G:/MNIST_data/test/mnist_train.tfrecords\"\n",
    "    batch = read_and_decode(tr_tf_path)\n",
    "#     batch = get_tf(batch_size=100, Train=False)\n",
    "#     init_op = tf.global_variables_initializer() \n",
    "      \n",
    "    with tf.Session() as sess: #开始一个会话\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "#         sess.run(tf.local_variables_initializer())\n",
    "#         sess.run(init_op)    \n",
    "        coord=tf.train.Coordinator()    \n",
    "        threads= tf.train.start_queue_runners(coord=coord)  \n",
    "        \n",
    "        \n",
    "        for i in range(num_samples_):    \n",
    "            example, lab = sess.run(batch)#在会话中取出image和label\n",
    "#             print(example.shape, lab.shape)\n",
    "            img=Image.fromarray(example,'L')#这里Image是之前提到的\n",
    "    \n",
    "#             for index, name in enumerate(classes):\n",
    "#                 if lab == index:\n",
    "#                     check_folder('G:/MNIST_data/'+name)\n",
    "#                     img.save('G:/MNIST_data/'+name+'/'+str(i)+'.png')\n",
    "                    \n",
    "#             for j in np.arange(100):\n",
    "\n",
    "#                     # np.arange()函数返回一个有终点和起点的固定步长的排列\n",
    "#                 img=Image.fromarray(example[j],'L')\n",
    "#                 print('label: %d' % lab[j])\n",
    "\n",
    "#                 plt.imshow(img)\n",
    "\n",
    "#                 title = classes[int(lab[j])]\n",
    "\n",
    "#                 plt.title(title)\n",
    "                    \n",
    "#                 plt.axis('off')\n",
    "                    \n",
    "#                 plt.show()     \n",
    "        \n",
    "            \n",
    "            if i == 6000:\n",
    "                print(lab)\n",
    "                plt.imshow(img)\n",
    "#             if lab == 1:\n",
    "#                 check_folder('G:/MNIST_data/'+str(lab))\n",
    "#                 img.save('G:/MNIST_data/'+str(lab)+'/'+str(i)+'.png')\n",
    "                    \n",
    "#             if lab==2:\n",
    "#                 check_folder('G:/MNIST_data/'+str(lab))\n",
    "#                 img.save('G:/MNIST_data/'+str(lab)+'/'+str(i)+'.png')#存下图片;注意cwd后边加上‘/’ \n",
    "#             if lab==3:\n",
    "#                 check_folder('G:/MNIST_data/'+str(lab))\n",
    "#                 img.save('G:/MNIST_data/'+str(lab)+'/'+str(i)+'.png')\n",
    "#             if lab==4:\n",
    "#                 check_folder('G:/MNIST_data/'+str(lab))\n",
    "#                 img.save('G:/MNIST_data/'+str(lab)+'/'+str(i)+'.png')            \n",
    "        coord.request_stop()\n",
    "        coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "PreWork.py\n",
    "\n",
    "功能：实现对指定大小的生成图片进行sample与label分类制作\n",
    "\n",
    "获得神经网络输入的get_files文件，同时为了方便网络的训练，输入数据进行batch处理。\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import *\n",
    "\n",
    " \n",
    "\n",
    "angry = []\n",
    "\n",
    "label_angry = []\n",
    "\n",
    "disgusted = []\n",
    "\n",
    "label_disgusted = []\n",
    "\n",
    "fearful = []\n",
    "\n",
    "label_fearful = []\n",
    "\n",
    "happy = []\n",
    "\n",
    "label_happy = []\n",
    "\n",
    "sadness = []\n",
    "\n",
    "label_sadness = []\n",
    "\n",
    "surprised = []\n",
    "\n",
    "label_surprised = []\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "def get_file(file_dir):\n",
    "\n",
    "    # step1：获取路径下所有的图片路径名，存放到\n",
    "\n",
    "    # 对应的列表中，同时贴上标签，存放到label列表中。\n",
    "\n",
    "    for file in os.listdir(file_dir + '/0'):\n",
    "\n",
    "        angry.append(file_dir + '/0' + '/' + file)\n",
    "\n",
    "        label_angry.append(0)\n",
    "\n",
    "    for file in os.listdir(file_dir + '/1'):\n",
    "\n",
    "        disgusted.append(file_dir + '/1' + '/' + file)\n",
    "\n",
    "        label_disgusted.append(1)\n",
    "\n",
    "    for file in os.listdir(file_dir + '/2'):\n",
    "\n",
    "        fearful.append(file_dir + '/2' + '/' + file)\n",
    "\n",
    "        label_fearful.append(2)\n",
    "\n",
    "    for file in os.listdir(file_dir + '/3'):\n",
    "\n",
    "        happy.append(file_dir + '/3' + '/' + file)\n",
    "\n",
    "        label_happy.append(3)\n",
    "\n",
    "    for file in os.listdir(file_dir + '/4'):\n",
    "\n",
    "        sadness.append(file_dir + '/4' + '/' + file)\n",
    "\n",
    "        label_sadness.append(4)\n",
    "\n",
    "    for file in os.listdir(file_dir + '/5'):\n",
    "\n",
    "        surprised.append(file_dir + '/5' + '/' + file)\n",
    "\n",
    "        label_surprised.append(5)\n",
    "\n",
    " \n",
    "\n",
    "    # 打印出提取图片的情况，检测是否正确提取\n",
    "\n",
    "    print(\"There are %d 0\\nThere are %d 1\\nThere are %d 2\\n\" %(len(angry), len(disgusted), len(fearful)),end=\"\")\n",
    "\n",
    "    print(\"There are %d 3\\nThere are %d 4\\nThere are %d 5\\n\" %(len(happy),len(sadness),len(surprised)))\n",
    "\n",
    " \n",
    "\n",
    "    # step2：对生成的图片路径和标签List做打乱处理把所有的合起来组成一个list（img和lab）\n",
    "\n",
    "    # 合并数据numpy.hstack(tup)\n",
    "\n",
    "    # tup可以是python中的元组（tuple）、列表（list），或者numpy中数组（array），函数作用是将tup在水平方向上（按列顺序）合并\n",
    "\n",
    "    image_list = np.hstack((angry, disgusted, fearful, happy, sadness, surprised))\n",
    "\n",
    "    label_list = np.hstack((label_angry, label_disgusted, label_fearful, label_happy, label_sadness, label_surprised))\n",
    "\n",
    "    # 利用shuffle，转置、随机打乱\n",
    "\n",
    "    temp = np.array([image_list, label_list])   # 转换成2维矩阵 [2, num]\n",
    "\n",
    "    temp = temp.transpose()     # 转置  [num, 2]\n",
    "\n",
    "    # numpy.transpose(a, axes=None) 作用：将输入的array转置，并返回转置后的array\n",
    "\n",
    "    np.random.shuffle(temp)     # 按行随机打乱顺序函数 np.random.permutation(temp)\n",
    "#     print(temp.shape)\n",
    " \n",
    "\n",
    "    # 将所有的img和lab转换成list\n",
    "\n",
    "    all_image_list = list(temp[:, 0])    # 取出第0列数据，即图片路径\n",
    "\n",
    "    all_label_list = list(temp[:, 1])    # 取出第1列数据，即图片标签\n",
    "#     print(all_image_list,'******', all_label_list)\n",
    "    \n",
    "    label_list = [int(i) for i in label_list]   # 转换成int数据类型\n",
    "\n",
    "\n",
    "    ''' \n",
    "\n",
    "    # 将所得List分为两部分，一部分用来训练tra，一部分用来测试val\n",
    "\n",
    "    n_sample = len(all_label_list)\n",
    "\n",
    "    n_val = int(math.ceil(n_sample * ratio))  # 测试样本数, ratio是测试集的比例\n",
    "\n",
    "    n_train = n_sample - n_val  # 训练样本数\n",
    "\n",
    "\n",
    "\n",
    "    tra_images = all_image_list[0:n_train]\n",
    "\n",
    "    tra_labels = all_label_list[0:n_train]\n",
    "\n",
    "    tra_labels = [int(float(i)) for i in tra_labels]   # 转换成int数据类型\n",
    "\n",
    "    val_images = all_image_list[n_train:-1]\n",
    "\n",
    "    val_labels = all_label_list[n_train:-1]\n",
    "\n",
    "    val_labels = [int(float(i)) for i in val_labels]   # 转换成int数据类型\n",
    "\n",
    "\n",
    "\n",
    "    return tra_images, tra_labels, val_images, val_labels\n",
    "\n",
    "    '''\n",
    "\n",
    "    return image_list, label_list\n",
    "\n",
    "# file_dir = 'G:/MNIST_data/test/'\n",
    "# get_file(file_dir)\n",
    "\n",
    "# 将image和label转为list格式数据，因为后边用到的的一些tensorflow函数接收的是list格式数据\n",
    "\n",
    "# 为了方便网络的训练，输入数据进行batch处理\n",
    "\n",
    "# image_W, image_H, ：图像高度和宽度\n",
    "\n",
    "# batch_size：每个batch要放多少张图片\n",
    "\n",
    "# capacity：一个队列最大多少\n",
    "\n",
    "def get_batch(image, label, image_W, image_H, batch_size, capacity):\n",
    "\n",
    "    # step1：将上面生成的List传入get_batch() ，转换类型，产生一个输入队列queue\n",
    "\n",
    "    # tf.cast()用来做类型转换\n",
    "\n",
    "    image = tf.cast(image, tf.string)   # 可变长度的字节数组.每一个张量元素都是一个字节数组\n",
    "\n",
    "    label = tf.cast(label, tf.int32)\n",
    "\n",
    "    # tf.train.slice_input_producer是一个tensor生成器\n",
    "\n",
    "    # 作用是按照设定，每次从一个tensor列表中按顺序或者随机抽取出一个tensor放入文件名队列。\n",
    "\n",
    "    input_queue = tf.train.slice_input_producer([image, label])\n",
    "\n",
    "    label = input_queue[1]\n",
    "\n",
    "    image_contents = tf.read_file(input_queue[0])   # tf.read_file()从队列中读取图像\n",
    "\n",
    " \n",
    "\n",
    "    # step2：将图像解码，使用相同类型的图像\n",
    "\n",
    "    image = tf.image.decode_jpeg(image_contents, channels=3)\n",
    "\n",
    "    # jpeg或者jpg格式都用decode_jpeg函数，其他格式可以去查看官方文档\n",
    "\n",
    " \n",
    "\n",
    "    # step3：数据预处理，对图像进行旋转、缩放、裁剪、归一化等操作，让计算出的模型更健壮。\n",
    "\n",
    "    image = tf.image.resize_image_with_crop_or_pad(image, image_W, image_H)\n",
    "\n",
    "    # 对resize后的图片进行标准化处理\n",
    "\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "\n",
    " \n",
    "\n",
    "    # step4：生成batch\n",
    "\n",
    "    # image_batch: 4D tensor [batch_size, width, height, 3], dtype = tf.float32\n",
    "\n",
    "    # label_batch: 1D tensor [batch_size], dtype = tf.int32\n",
    "\n",
    "    image_batch, label_batch = tf.train.batch([image, label], batch_size=batch_size, num_threads=16, capacity=capacity)\n",
    "\n",
    " \n",
    "\n",
    "    # 重新排列label，行数为[batch_size]\n",
    "\n",
    "    label_batch = tf.reshape(label_batch, [batch_size])\n",
    "\n",
    "    # image_batch = tf.cast(image_batch, tf.uint8)    # 显示彩色图像\n",
    "\n",
    "    image_batch = tf.cast(image_batch, tf.float32)    # 显示灰度图\n",
    "\n",
    "    # print(label_batch) Tensor(\"Reshape:0\", shape=(6,), dtype=int32)\n",
    "\n",
    "    return image_batch, label_batch\n",
    "\n",
    "    # 获取两个batch，两个batch即为传入神经网络的数据\n",
    "# get_batch(image, label, image_W, image_H, batch_size, capacity)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "def PreWork():\n",
    "\n",
    "    # 对预处理的数据进行可视化，查看预处理的效果\n",
    "\n",
    "    IMG_W = 28\n",
    "\n",
    "    IMG_H = 28\n",
    "\n",
    "    BATCH_SIZE = 6\n",
    "\n",
    "    CAPACITY = 64\n",
    "\n",
    "\n",
    "\n",
    "    train_dir = 'G:/MNIST_data/test/'\n",
    "\n",
    "\n",
    "\n",
    "    # image_list, label_list, val_images, val_labels = get_file(train_dir)\n",
    "\n",
    "    image_list, label_list = get_file(train_dir)\n",
    "\n",
    "    image_batch, label_batch = get_batch(image_list, label_list, IMG_W, IMG_H, BATCH_SIZE, CAPACITY)\n",
    "\n",
    "    print(label_batch.shape)\n",
    "\n",
    "\n",
    "\n",
    "    lists = ('0', '1', '2', '3', '4', '5')\n",
    "\n",
    "\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        coord = tf.train.Coordinator()  # 创建一个线程协调器，用来管理之后在Session中启动的所有线程\n",
    "\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "        try:\n",
    "\n",
    "            while not coord.should_stop() and i < 1:\n",
    "\n",
    "                # 提取出两个batch的图片并可视化。\n",
    "\n",
    "                img, label = sess.run([image_batch, label_batch])  # 在会话中取出img和label\n",
    "\n",
    "                # img = tf.cast(img, tf.uint8)\n",
    "\n",
    "\n",
    "\n",
    "                '''\n",
    "\n",
    "                1、range()返回的是range object，而np.arange()返回的是numpy.ndarray()\n",
    "\n",
    "                range(start, end, step)，返回一个list对象，起始值为start，终止值为end，但不含终止值，步长为step。只能创建int型list。\n",
    "\n",
    "                arange(start, end, step)，与range()类似，但是返回一个array对象。需要引入import numpy as np，并且arange可以使用float型数据。\n",
    "\n",
    "                \n",
    "\n",
    "                2、range()不支持步长为小数，np.arange()支持步长为小数\n",
    "\n",
    "                \n",
    "\n",
    "                3、两者都可用于迭代\n",
    "\n",
    "                range尽可用于迭代，而np.nrange作用远不止于此，它是一个序列，可被当做向量使用。\n",
    "\n",
    "                '''\n",
    "\n",
    "                for j in np.arange(BATCH_SIZE):\n",
    "\n",
    "                    # np.arange()函数返回一个有终点和起点的固定步长的排列\n",
    "\n",
    "                    print('label: %d' % label[j])\n",
    "\n",
    "                    plt.imshow(img[j, :, :, :])\n",
    "\n",
    "                    title = lists[int(label[j])]\n",
    "\n",
    "                    plt.title(title)\n",
    "                    \n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                    plt.show()\n",
    "\n",
    "                i += 1\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "\n",
    "            print('done!')\n",
    "\n",
    "        finally:\n",
    "\n",
    "            coord.request_stop()\n",
    "\n",
    "        coord.join(threads)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    PreWork()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
