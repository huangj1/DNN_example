{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lenet-5:\n",
    "<img src=\"Lenet5/Lenet5.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "IMAGE_SIZE = 28  # 输入维度大小\n",
    "NUM_CHANNELS = 1  # 通道数\n",
    "CONV1_SIZE = 5  # 卷积核维度\n",
    "CONV1_KERNEL_NUM = 32  # 卷积核个数\n",
    "CONV2_SIZE = 5\n",
    "CONV2_KERNEL_NUM = 64\n",
    "FC_SIZE = 512  # 全连接层节点\n",
    "OUTPUT_SIZE = 10  # 输出节点（分类数目）\n",
    "\n",
    "def create_placeholder():\n",
    "    with tf.name_scope('input_data'):\n",
    "        X = tf.placeholder(tf.float32, [None, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS], name = 'X')\n",
    "        Y = tf.placeholder(tf.float32, [None, OUTPUT_SIZE], name = 'Y')\n",
    "#         image_shaped_input = tf.reshape(X, [-1, 28, 28, 1])\n",
    "        tf.summary.image('X_images', X, 10)\n",
    "    return X, Y\n",
    "\n",
    "def get_weight(shape, regularizer):  # 权重初始化  # tf.get_variable('weight', shape, initializer = tf.truncated_normal_initializer(stddev=0.1))\n",
    "    W = tf.Variable(tf.truncated_normal(shape, stddev=0.1), name = 'weight')\n",
    "    if regularizer != None:\n",
    "        tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(regularizer)(W))\n",
    "    tf.summary.histogram('weight', W)\n",
    "    return W\n",
    "\n",
    "def get_biasis(shape):  # 偏置初始化\n",
    "    b = tf.Variable(tf.zeros(shape), name = 'biasis')\n",
    "    tf.summary.histogram('biasis', b)\n",
    "    return b\n",
    "    \n",
    "def conv2d(X, W):  # 卷积操作，X: [N, H, W, C]\n",
    "    return tf.nn.conv2d(X, W, strides = [1,1,1,1], padding = 'SAME')\n",
    "\n",
    "def max_pool(X):  # 最大池化，2x2，步长2\n",
    "    return tf.nn.max_pool(X, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "\n",
    "def reshaped(pool):  # 全连接层维度拉直\n",
    "    pool_shape = pool.get_shape().as_list()\n",
    "#     print(pool_shape)\n",
    "    nodes = pool_shape[1] * pool_shape[2] * pool_shape[3]  # reshaped = tf.contrib.layers.flatten(pool2)\n",
    "    reshaped = tf.contrib.layers.flatten(pool)\n",
    "#     reshaped = tf.reshape(pool, [pool_shape[0], nodes])\n",
    "    return reshaped, nodes\n",
    "\n",
    "def forward(X, train = True, regularizer = 0.0001):  # 前向传播，train决定训练时使用dropout    \n",
    "    with tf.variable_scope('conv32_5x5'):  # 第一层\n",
    "        conv1_w = get_weight([CONV1_SIZE,CONV1_SIZE,NUM_CHANNELS,CONV1_KERNEL_NUM], regularizer)\n",
    "        conv1_b = get_biasis([CONV1_KERNEL_NUM])\n",
    "        conv1 = conv2d(X, conv1_w)\n",
    "        relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_b))\n",
    "        pool1 = max_pool(relu1)\n",
    "        \n",
    "    with tf.variable_scope('conv64_5x5'):  # 第二层\n",
    "        conv2_w = get_weight([CONV2_SIZE,CONV2_SIZE,CONV1_KERNEL_NUM,CONV2_KERNEL_NUM], regularizer)\n",
    "        conv2_b = get_biasis([CONV2_KERNEL_NUM])\n",
    "        conv2 = conv2d(pool1, conv2_w)\n",
    "        relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_b))\n",
    "        pool2 = max_pool(relu2)\n",
    "        \n",
    "    with tf.variable_scope('fc_512'):  # 全连接层\n",
    "        reshaped1, nodes = reshaped(pool2)\n",
    "        fc1_w = get_weight([nodes, FC_SIZE], regularizer)\n",
    "        fc1_b = get_biasis([FC_SIZE])\n",
    "        fc1 = tf.nn.relu(tf.matmul(reshaped1, fc1_w) + fc1_b)\n",
    "        if train == True: fc1 = tf.nn.dropout(fc1, 0.5)  # 训练时dropout\n",
    "        \n",
    "    with tf.variable_scope('output_10'):  # 输出全连接层\n",
    "        o_w = get_weight([FC_SIZE, OUTPUT_SIZE], regularizer)\n",
    "        o_b = get_biasis([OUTPUT_SIZE])\n",
    "        y = tf.matmul(fc1, o_w) + o_b\n",
    "    \n",
    "    return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?,)\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[Node: input_producer_2/input_producer_2_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](input_producer_2, input_producer_2/Identity/_45)]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-dea6ae1bee28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mthreads\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_queue_runners\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoord\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m60000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mexample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;31m#         print(example.shape,lab.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;31m#         print(lab)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#读取frecords并还原\n",
    "#=======================================================================================\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def read_and_decode(filename):  \n",
    "    # 创建文件队列,不限读取的数量  \n",
    "    filename_queue = tf.train.string_input_producer([filename])  \n",
    "    # create a reader from file queue  \n",
    "    reader = tf.TFRecordReader()  \n",
    "    # reader从文件队列中读入一个序列化的样本  \n",
    "    _, serialized_example = reader.read(filename_queue)  \n",
    "    # get feature from serialized example  \n",
    "    # 解析符号化的样本  \n",
    "    features = tf.parse_single_example(  #按原保存的格式解析\n",
    "        serialized_example,  \n",
    "        features={  \n",
    "            'label': tf.FixedLenFeature([], tf.int64),  \n",
    "            'image_raw': tf.FixedLenFeature([], tf.string)  \n",
    "        })  \n",
    "    lab = features['label']  \n",
    "    img = features['image_raw']  \n",
    "    de_img = tf.decode_raw(img, tf.uint8) #图像解析为对应的像素数组\n",
    "    image = tf.reshape(de_img, [28, 28, 1]) # \n",
    "    images = tf.cast(image, tf.float32) * (1. / 255)\n",
    "    label = tf.cast(lab, tf.int32)\n",
    "    labels = tf.cast(tf.one_hot(label, 10), tf.float32)\n",
    "    return image, labels \n",
    "\n",
    "def get_tf(batch_size, Train=True):\n",
    "    if Train:\n",
    "        tf_path = tr_tf_path\n",
    "    else:\n",
    "        tf_path = te_tf_path\n",
    "    img, label = read_and_decode(tf_path)\n",
    "    img_batch, label_batch = tf.train.shuffle_batch([img,label],\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   num_threads=4,\n",
    "                                                   capacity=1000,\n",
    "                                                   min_after_dequeue=600)\n",
    "    img_batch = tf.cast(img_batch, tf.float32)\n",
    "    return img_batch, label_batch\n",
    "\n",
    "tr_tf_path, tr_img_path = 'G:/MNIST_data/train/train.tfrecords', 'G:/MNIST_data/train/'\n",
    "te_tf_path, te_img_path = 'G:/MNIST_data/test/mnist_test.tfrecords', 'G:/MNIST_data/test/'\n",
    "# batch = get_tf(256, Train=True)\n",
    "# # batch = read_and_decode(tr_tf_path)\n",
    "# with tf.Session() as sess:\n",
    "# #     sess.run(tf.initialize_all_variables())\n",
    "#     coord=tf.train.Coordinator()    \n",
    "#     threads= tf.train.start_queue_runners(coord=coord)\n",
    "#     for i in range(60000):\n",
    "#         example, lab = sess.run(batch)\n",
    "#         print(example.shape,lab.shape)\n",
    "#         print(lab)\n",
    "    \n",
    "    \n",
    "#     coord.request_stop()\n",
    "#     coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-46ec2d6ca70c>:31: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./Lenet5/model/Lenet-5_model.ckpt-200\n",
      "INFO: After 201 training iteration(s), loss is 2.94561, batch_train accuracy is 0.1328\n",
      "INFO: After 202 training iteration(s), loss is 2.96005, batch_train accuracy is 0.1035\n",
      "INFO: After 203 training iteration(s), loss is 2.94954, batch_train accuracy is 0.1172\n",
      "INFO: After 204 training iteration(s), loss is 2.96064, batch_train accuracy is 0.1191\n",
      "INFO: After 205 training iteration(s), loss is 2.95829, batch_train accuracy is 0.1074\n",
      "INFO: After 206 training iteration(s), loss is 2.96427, batch_train accuracy is 0.1250\n",
      "INFO: After 207 training iteration(s), loss is 2.95305, batch_train accuracy is 0.1250\n",
      "INFO: After 208 training iteration(s), loss is 2.94703, batch_train accuracy is 0.1309\n",
      "INFO: After 209 training iteration(s), loss is 2.95797, batch_train accuracy is 0.1406\n",
      "INFO: After 210 training iteration(s), loss is 2.94903, batch_train accuracy is 0.1270\n",
      "INFO: After 211 training iteration(s), loss is 2.95625, batch_train accuracy is 0.1309\n",
      "INFO: After 212 training iteration(s), loss is 2.95468, batch_train accuracy is 0.1250\n",
      "INFO: After 213 training iteration(s), loss is 2.95724, batch_train accuracy is 0.1133\n",
      "INFO: After 214 training iteration(s), loss is 2.95623, batch_train accuracy is 0.1016\n",
      "INFO: After 215 training iteration(s), loss is 2.95505, batch_train accuracy is 0.0996\n",
      "INFO: After 216 training iteration(s), loss is 2.94498, batch_train accuracy is 0.1582\n",
      "INFO: After 217 training iteration(s), loss is 2.94798, batch_train accuracy is 0.1387\n",
      "INFO: After 218 training iteration(s), loss is 2.96269, batch_train accuracy is 0.0957\n",
      "INFO: After 219 training iteration(s), loss is 2.94564, batch_train accuracy is 0.1348\n",
      "INFO: After 220 training iteration(s), loss is 2.95447, batch_train accuracy is 0.1035\n",
      "INFO: After 221 training iteration(s), loss is 2.95582, batch_train accuracy is 0.1230\n",
      "INFO: After 222 training iteration(s), loss is 2.95601, batch_train accuracy is 0.1289\n",
      "INFO: After 223 training iteration(s), loss is 2.94868, batch_train accuracy is 0.1172\n",
      "INFO: After 224 training iteration(s), loss is 2.94807, batch_train accuracy is 0.1152\n",
      "INFO: After 225 training iteration(s), loss is 2.95620, batch_train accuracy is 0.1465\n",
      "INFO: After 226 training iteration(s), loss is 2.95210, batch_train accuracy is 0.1113\n",
      "INFO: After 227 training iteration(s), loss is 2.94738, batch_train accuracy is 0.1133\n",
      "INFO: After 228 training iteration(s), loss is 2.95893, batch_train accuracy is 0.1016\n",
      "INFO: After 229 training iteration(s), loss is 2.96098, batch_train accuracy is 0.1191\n",
      "INFO: After 230 training iteration(s), loss is 2.95444, batch_train accuracy is 0.1133\n",
      "INFO: After 231 training iteration(s), loss is 2.95070, batch_train accuracy is 0.0918\n",
      "INFO: After 232 training iteration(s), loss is 2.94789, batch_train accuracy is 0.1113\n",
      "INFO: After 233 training iteration(s), loss is 2.94897, batch_train accuracy is 0.1289\n",
      "INFO: After 234 training iteration(s), loss is 2.95517, batch_train accuracy is 0.1230\n",
      "INFO: After 235 training iteration(s), loss is 2.95189, batch_train accuracy is 0.0996\n",
      "INFO: After 236 training iteration(s), loss is 2.94887, batch_train accuracy is 0.1250\n",
      "INFO: After 237 training iteration(s), loss is 2.95589, batch_train accuracy is 0.0859\n",
      "INFO: After 238 training iteration(s), loss is 2.95321, batch_train accuracy is 0.1230\n",
      "INFO: After 239 training iteration(s), loss is 2.95384, batch_train accuracy is 0.1133\n",
      "INFO: After 240 training iteration(s), loss is 2.96453, batch_train accuracy is 0.0938\n",
      "INFO: After 241 training iteration(s), loss is 2.95689, batch_train accuracy is 0.1289\n",
      "INFO: After 242 training iteration(s), loss is 2.94801, batch_train accuracy is 0.1191\n",
      "INFO: After 243 training iteration(s), loss is 2.95505, batch_train accuracy is 0.1250\n",
      "INFO: After 244 training iteration(s), loss is 2.94647, batch_train accuracy is 0.1406\n",
      "INFO: After 245 training iteration(s), loss is 2.94730, batch_train accuracy is 0.1484\n",
      "INFO: After 246 training iteration(s), loss is 2.94829, batch_train accuracy is 0.1211\n",
      "INFO: After 247 training iteration(s), loss is 2.94538, batch_train accuracy is 0.1426\n",
      "INFO: After 248 training iteration(s), loss is 2.95012, batch_train accuracy is 0.1484\n",
      "INFO: After 249 training iteration(s), loss is 2.94886, batch_train accuracy is 0.1348\n",
      "INFO: After 250 training iteration(s), loss is 2.94881, batch_train accuracy is 0.1328\n",
      "INFO: After 251 training iteration(s), loss is 2.95197, batch_train accuracy is 0.1113\n",
      "INFO: After 252 training iteration(s), loss is 2.95952, batch_train accuracy is 0.1309\n",
      "INFO: After 253 training iteration(s), loss is 2.95524, batch_train accuracy is 0.1348\n",
      "INFO: After 254 training iteration(s), loss is 2.95169, batch_train accuracy is 0.1094\n",
      "INFO: After 255 training iteration(s), loss is 2.95536, batch_train accuracy is 0.1152\n",
      "INFO: After 256 training iteration(s), loss is 2.95435, batch_train accuracy is 0.1055\n",
      "INFO: After 257 training iteration(s), loss is 2.94563, batch_train accuracy is 0.1387\n",
      "INFO: After 258 training iteration(s), loss is 2.95488, batch_train accuracy is 0.1250\n",
      "INFO: After 259 training iteration(s), loss is 2.94604, batch_train accuracy is 0.1074\n",
      "INFO: After 260 training iteration(s), loss is 2.94815, batch_train accuracy is 0.1328\n",
      "INFO: After 261 training iteration(s), loss is 2.94603, batch_train accuracy is 0.1172\n",
      "INFO: After 262 training iteration(s), loss is 2.95020, batch_train accuracy is 0.1152\n",
      "INFO: After 263 training iteration(s), loss is 2.94520, batch_train accuracy is 0.1367\n",
      "INFO: After 264 training iteration(s), loss is 2.94818, batch_train accuracy is 0.1387\n",
      "INFO: After 265 training iteration(s), loss is 2.94554, batch_train accuracy is 0.1309\n",
      "INFO: After 266 training iteration(s), loss is 2.93748, batch_train accuracy is 0.1484\n",
      "INFO: After 267 training iteration(s), loss is 2.94303, batch_train accuracy is 0.1406\n",
      "INFO: After 268 training iteration(s), loss is 2.94783, batch_train accuracy is 0.1309\n",
      "INFO: After 269 training iteration(s), loss is 2.95192, batch_train accuracy is 0.1270\n",
      "INFO: After 270 training iteration(s), loss is 2.94475, batch_train accuracy is 0.1582\n",
      "INFO: After 271 training iteration(s), loss is 2.94327, batch_train accuracy is 0.1445\n",
      "INFO: After 272 training iteration(s), loss is 2.95102, batch_train accuracy is 0.1309\n",
      "INFO: After 273 training iteration(s), loss is 2.95673, batch_train accuracy is 0.1133\n",
      "INFO: After 274 training iteration(s), loss is 2.94331, batch_train accuracy is 0.1074\n",
      "INFO: After 275 training iteration(s), loss is 2.94382, batch_train accuracy is 0.1250\n",
      "INFO: After 276 training iteration(s), loss is 2.94635, batch_train accuracy is 0.1250\n",
      "INFO: After 277 training iteration(s), loss is 2.94716, batch_train accuracy is 0.1172\n",
      "INFO: After 278 training iteration(s), loss is 2.95877, batch_train accuracy is 0.1152\n",
      "INFO: After 279 training iteration(s), loss is 2.93840, batch_train accuracy is 0.1191\n",
      "INFO: After 280 training iteration(s), loss is 2.94705, batch_train accuracy is 0.1211\n",
      "INFO: After 281 training iteration(s), loss is 2.94100, batch_train accuracy is 0.1367\n",
      "INFO: After 282 training iteration(s), loss is 2.94115, batch_train accuracy is 0.1387\n",
      "INFO: After 283 training iteration(s), loss is 2.95151, batch_train accuracy is 0.1211\n",
      "INFO: After 284 training iteration(s), loss is 2.95369, batch_train accuracy is 0.0996\n",
      "INFO: After 285 training iteration(s), loss is 2.94539, batch_train accuracy is 0.0957\n",
      "INFO: After 286 training iteration(s), loss is 2.94601, batch_train accuracy is 0.1152\n",
      "INFO: After 287 training iteration(s), loss is 2.94903, batch_train accuracy is 0.1348\n",
      "INFO: After 288 training iteration(s), loss is 2.95040, batch_train accuracy is 0.1270\n",
      "INFO: After 289 training iteration(s), loss is 2.94275, batch_train accuracy is 0.1426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: After 290 training iteration(s), loss is 2.93490, batch_train accuracy is 0.1465\n",
      "INFO: After 291 training iteration(s), loss is 2.95068, batch_train accuracy is 0.1094\n",
      "INFO: After 292 training iteration(s), loss is 2.94672, batch_train accuracy is 0.1230\n",
      "INFO: After 293 training iteration(s), loss is 2.95667, batch_train accuracy is 0.1074\n",
      "INFO: After 294 training iteration(s), loss is 2.94537, batch_train accuracy is 0.1270\n",
      "INFO: After 295 training iteration(s), loss is 2.93512, batch_train accuracy is 0.1406\n",
      "INFO: After 296 training iteration(s), loss is 2.93885, batch_train accuracy is 0.1328\n",
      "INFO: After 297 training iteration(s), loss is 2.95442, batch_train accuracy is 0.1387\n",
      "INFO: After 298 training iteration(s), loss is 2.94102, batch_train accuracy is 0.1406\n",
      "INFO: After 299 training iteration(s), loss is 2.95054, batch_train accuracy is 0.1348\n",
      "INFO: After 300 training iteration(s), loss is 2.93416, batch_train accuracy is 0.1562\n",
      "Lenet-5_model-300.ckpt saved!\n",
      "INFO: After 301 training iteration(s), loss is 2.93796, batch_train accuracy is 0.1426\n",
      "INFO: After 302 training iteration(s), loss is 2.94618, batch_train accuracy is 0.1289\n",
      "INFO: After 303 training iteration(s), loss is 2.94433, batch_train accuracy is 0.1191\n",
      "INFO: After 304 training iteration(s), loss is 2.93966, batch_train accuracy is 0.1250\n",
      "INFO: After 305 training iteration(s), loss is 2.94112, batch_train accuracy is 0.1328\n",
      "INFO: After 306 training iteration(s), loss is 2.94084, batch_train accuracy is 0.1328\n",
      "INFO: After 307 training iteration(s), loss is 2.95128, batch_train accuracy is 0.1387\n",
      "INFO: After 308 training iteration(s), loss is 2.94595, batch_train accuracy is 0.1270\n",
      "INFO: After 309 training iteration(s), loss is 2.93483, batch_train accuracy is 0.1660\n",
      "INFO: After 310 training iteration(s), loss is 2.93874, batch_train accuracy is 0.1582\n",
      "INFO: After 311 training iteration(s), loss is 2.93865, batch_train accuracy is 0.1328\n",
      "INFO: After 312 training iteration(s), loss is 2.94522, batch_train accuracy is 0.1094\n",
      "INFO: After 313 training iteration(s), loss is 2.94468, batch_train accuracy is 0.1172\n",
      "INFO: After 314 training iteration(s), loss is 2.93392, batch_train accuracy is 0.1426\n",
      "INFO: After 315 training iteration(s), loss is 2.95067, batch_train accuracy is 0.1387\n",
      "INFO: After 316 training iteration(s), loss is 2.94240, batch_train accuracy is 0.1250\n",
      "INFO: After 317 training iteration(s), loss is 2.93773, batch_train accuracy is 0.1445\n",
      "After 1 training epoch(s)(X117), loss is 2.94896, train accuracy is 0.1255\n",
      "Lenet-5_model-1x117 saved!\n",
      "INFO: After 318 training iteration(s), loss is 2.93962, batch_train accuracy is 0.1250\n",
      "INFO: After 319 training iteration(s), loss is 2.94409, batch_train accuracy is 0.1230\n",
      "INFO: After 320 training iteration(s), loss is 2.93638, batch_train accuracy is 0.1543\n",
      "INFO: After 321 training iteration(s), loss is 2.94509, batch_train accuracy is 0.1172\n",
      "INFO: After 322 training iteration(s), loss is 2.94898, batch_train accuracy is 0.1445\n",
      "INFO: After 323 training iteration(s), loss is 2.94137, batch_train accuracy is 0.1250\n",
      "INFO: After 324 training iteration(s), loss is 2.95114, batch_train accuracy is 0.1328\n",
      "INFO: After 325 training iteration(s), loss is 2.93840, batch_train accuracy is 0.1484\n",
      "INFO: After 326 training iteration(s), loss is 2.94705, batch_train accuracy is 0.1484\n",
      "INFO: After 327 training iteration(s), loss is 2.95033, batch_train accuracy is 0.1289\n",
      "INFO: After 328 training iteration(s), loss is 2.93273, batch_train accuracy is 0.1523\n",
      "INFO: After 329 training iteration(s), loss is 2.94406, batch_train accuracy is 0.1016\n",
      "INFO: After 330 training iteration(s), loss is 2.95137, batch_train accuracy is 0.1230\n",
      "INFO: After 331 training iteration(s), loss is 2.93969, batch_train accuracy is 0.1270\n",
      "INFO: After 332 training iteration(s), loss is 2.94300, batch_train accuracy is 0.1309\n",
      "INFO: After 333 training iteration(s), loss is 2.93557, batch_train accuracy is 0.1621\n",
      "INFO: After 334 training iteration(s), loss is 2.93495, batch_train accuracy is 0.1367\n",
      "INFO: After 335 training iteration(s), loss is 2.93919, batch_train accuracy is 0.1406\n",
      "INFO: After 336 training iteration(s), loss is 2.93430, batch_train accuracy is 0.1309\n",
      "INFO: After 337 training iteration(s), loss is 2.94130, batch_train accuracy is 0.1016\n",
      "INFO: After 338 training iteration(s), loss is 2.94308, batch_train accuracy is 0.1191\n",
      "INFO: After 339 training iteration(s), loss is 2.94269, batch_train accuracy is 0.1289\n",
      "INFO: After 340 training iteration(s), loss is 2.93322, batch_train accuracy is 0.1309\n",
      "INFO: After 341 training iteration(s), loss is 2.94037, batch_train accuracy is 0.1465\n",
      "INFO: After 342 training iteration(s), loss is 2.95586, batch_train accuracy is 0.1328\n",
      "INFO: After 343 training iteration(s), loss is 2.94014, batch_train accuracy is 0.1426\n",
      "INFO: After 344 training iteration(s), loss is 2.93829, batch_train accuracy is 0.1562\n",
      "INFO: After 345 training iteration(s), loss is 2.93969, batch_train accuracy is 0.1172\n",
      "INFO: After 346 training iteration(s), loss is 2.94454, batch_train accuracy is 0.1250\n",
      "INFO: After 347 training iteration(s), loss is 2.93950, batch_train accuracy is 0.1406\n",
      "INFO: After 348 training iteration(s), loss is 2.94220, batch_train accuracy is 0.1289\n",
      "INFO: After 349 training iteration(s), loss is 2.93727, batch_train accuracy is 0.1465\n",
      "INFO: After 350 training iteration(s), loss is 2.94750, batch_train accuracy is 0.1133\n",
      "INFO: After 351 training iteration(s), loss is 2.94507, batch_train accuracy is 0.1504\n",
      "INFO: After 352 training iteration(s), loss is 2.92887, batch_train accuracy is 0.1406\n",
      "INFO: After 353 training iteration(s), loss is 2.94279, batch_train accuracy is 0.1172\n",
      "INFO: After 354 training iteration(s), loss is 2.94096, batch_train accuracy is 0.1465\n",
      "INFO: After 355 training iteration(s), loss is 2.94266, batch_train accuracy is 0.1543\n",
      "INFO: After 356 training iteration(s), loss is 2.94057, batch_train accuracy is 0.1348\n",
      "INFO: After 357 training iteration(s), loss is 2.94099, batch_train accuracy is 0.1582\n",
      "INFO: After 358 training iteration(s), loss is 2.94351, batch_train accuracy is 0.1289\n",
      "INFO: After 359 training iteration(s), loss is 2.94149, batch_train accuracy is 0.1660\n",
      "INFO: After 360 training iteration(s), loss is 2.93553, batch_train accuracy is 0.1348\n",
      "INFO: After 361 training iteration(s), loss is 2.94497, batch_train accuracy is 0.1250\n",
      "INFO: After 362 training iteration(s), loss is 2.94112, batch_train accuracy is 0.1406\n",
      "INFO: After 363 training iteration(s), loss is 2.93335, batch_train accuracy is 0.1621\n",
      "INFO: After 364 training iteration(s), loss is 2.92748, batch_train accuracy is 0.1367\n",
      "INFO: After 365 training iteration(s), loss is 2.94430, batch_train accuracy is 0.1289\n",
      "INFO: After 366 training iteration(s), loss is 2.92655, batch_train accuracy is 0.1562\n",
      "INFO: After 367 training iteration(s), loss is 2.93921, batch_train accuracy is 0.1523\n",
      "INFO: After 368 training iteration(s), loss is 2.94518, batch_train accuracy is 0.1113\n",
      "INFO: After 369 training iteration(s), loss is 2.93821, batch_train accuracy is 0.1406\n",
      "INFO: After 370 training iteration(s), loss is 2.95612, batch_train accuracy is 0.1250\n",
      "INFO: After 371 training iteration(s), loss is 2.93419, batch_train accuracy is 0.1484\n",
      "INFO: After 372 training iteration(s), loss is 2.93588, batch_train accuracy is 0.1602\n",
      "INFO: After 373 training iteration(s), loss is 2.94583, batch_train accuracy is 0.1172\n",
      "INFO: After 374 training iteration(s), loss is 2.94304, batch_train accuracy is 0.1387\n",
      "INFO: After 375 training iteration(s), loss is 2.93808, batch_train accuracy is 0.1406\n",
      "INFO: After 376 training iteration(s), loss is 2.93336, batch_train accuracy is 0.1484\n",
      "INFO: After 377 training iteration(s), loss is 2.93813, batch_train accuracy is 0.1348\n",
      "INFO: After 378 training iteration(s), loss is 2.93806, batch_train accuracy is 0.1445\n",
      "INFO: After 379 training iteration(s), loss is 2.92675, batch_train accuracy is 0.1621\n",
      "INFO: After 380 training iteration(s), loss is 2.93327, batch_train accuracy is 0.1582\n",
      "INFO: After 381 training iteration(s), loss is 2.94065, batch_train accuracy is 0.1289\n",
      "INFO: After 382 training iteration(s), loss is 2.94124, batch_train accuracy is 0.1348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: After 383 training iteration(s), loss is 2.92435, batch_train accuracy is 0.1445\n",
      "INFO: After 384 training iteration(s), loss is 2.93753, batch_train accuracy is 0.1484\n",
      "INFO: After 385 training iteration(s), loss is 2.93079, batch_train accuracy is 0.1309\n",
      "INFO: After 386 training iteration(s), loss is 2.92974, batch_train accuracy is 0.1484\n",
      "INFO: After 387 training iteration(s), loss is 2.93652, batch_train accuracy is 0.1641\n",
      "INFO: After 388 training iteration(s), loss is 2.93959, batch_train accuracy is 0.1270\n",
      "INFO: After 389 training iteration(s), loss is 2.93377, batch_train accuracy is 0.1465\n",
      "INFO: After 390 training iteration(s), loss is 2.92820, batch_train accuracy is 0.1348\n",
      "INFO: After 391 training iteration(s), loss is 2.93738, batch_train accuracy is 0.1367\n",
      "INFO: After 392 training iteration(s), loss is 2.94219, batch_train accuracy is 0.1367\n",
      "INFO: After 393 training iteration(s), loss is 2.92844, batch_train accuracy is 0.1328\n",
      "INFO: After 394 training iteration(s), loss is 2.92704, batch_train accuracy is 0.1270\n",
      "INFO: After 395 training iteration(s), loss is 2.94328, batch_train accuracy is 0.1328\n",
      "INFO: After 396 training iteration(s), loss is 2.93061, batch_train accuracy is 0.1523\n",
      "INFO: After 397 training iteration(s), loss is 2.92834, batch_train accuracy is 0.1367\n",
      "INFO: After 398 training iteration(s), loss is 2.92902, batch_train accuracy is 0.1445\n",
      "INFO: After 399 training iteration(s), loss is 2.94119, batch_train accuracy is 0.1328\n",
      "INFO: After 400 training iteration(s), loss is 2.93039, batch_train accuracy is 0.1445\n",
      "Lenet-5_model-400.ckpt saved!\n",
      "INFO: After 401 training iteration(s), loss is 2.93728, batch_train accuracy is 0.1270\n",
      "INFO: After 402 training iteration(s), loss is 2.93390, batch_train accuracy is 0.1250\n",
      "INFO: After 403 training iteration(s), loss is 2.93070, batch_train accuracy is 0.1680\n",
      "INFO: After 404 training iteration(s), loss is 2.94288, batch_train accuracy is 0.1191\n",
      "INFO: After 405 training iteration(s), loss is 2.93767, batch_train accuracy is 0.1250\n",
      "INFO: After 406 training iteration(s), loss is 2.92979, batch_train accuracy is 0.1543\n",
      "INFO: After 407 training iteration(s), loss is 2.93851, batch_train accuracy is 0.1641\n",
      "INFO: After 408 training iteration(s), loss is 2.93332, batch_train accuracy is 0.1406\n",
      "INFO: After 409 training iteration(s), loss is 2.93031, batch_train accuracy is 0.1562\n",
      "INFO: After 410 training iteration(s), loss is 2.93672, batch_train accuracy is 0.1152\n",
      "INFO: After 411 training iteration(s), loss is 2.91942, batch_train accuracy is 0.1758\n",
      "INFO: After 412 training iteration(s), loss is 2.94325, batch_train accuracy is 0.1270\n",
      "INFO: After 413 training iteration(s), loss is 2.92595, batch_train accuracy is 0.1387\n",
      "INFO: After 414 training iteration(s), loss is 2.93594, batch_train accuracy is 0.1680\n",
      "INFO: After 415 training iteration(s), loss is 2.91635, batch_train accuracy is 0.1719\n",
      "INFO: After 416 training iteration(s), loss is 2.93452, batch_train accuracy is 0.1289\n",
      "INFO: After 417 training iteration(s), loss is 2.93383, batch_train accuracy is 0.1289\n",
      "INFO: After 418 training iteration(s), loss is 2.93569, batch_train accuracy is 0.1523\n",
      "INFO: After 419 training iteration(s), loss is 2.92281, batch_train accuracy is 0.1582\n",
      "INFO: After 420 training iteration(s), loss is 2.91922, batch_train accuracy is 0.1562\n",
      "INFO: After 421 training iteration(s), loss is 2.93206, batch_train accuracy is 0.1602\n",
      "INFO: After 422 training iteration(s), loss is 2.91988, batch_train accuracy is 0.1738\n",
      "INFO: After 423 training iteration(s), loss is 2.93840, batch_train accuracy is 0.1172\n",
      "INFO: After 424 training iteration(s), loss is 2.92744, batch_train accuracy is 0.1465\n",
      "INFO: After 425 training iteration(s), loss is 2.92646, batch_train accuracy is 0.1406\n",
      "INFO: After 426 training iteration(s), loss is 2.92764, batch_train accuracy is 0.1465\n",
      "INFO: After 427 training iteration(s), loss is 2.93547, batch_train accuracy is 0.1328\n",
      "INFO: After 428 training iteration(s), loss is 2.93523, batch_train accuracy is 0.1387\n",
      "INFO: After 429 training iteration(s), loss is 2.92852, batch_train accuracy is 0.1367\n",
      "INFO: After 430 training iteration(s), loss is 2.92971, batch_train accuracy is 0.1406\n",
      "INFO: After 431 training iteration(s), loss is 2.93402, batch_train accuracy is 0.1289\n",
      "INFO: After 432 training iteration(s), loss is 2.92801, batch_train accuracy is 0.1387\n",
      "INFO: After 433 training iteration(s), loss is 2.93889, batch_train accuracy is 0.1289\n",
      "INFO: After 434 training iteration(s), loss is 2.92377, batch_train accuracy is 0.1426\n",
      "After 2 training epoch(s)(X117), loss is 2.93669, train accuracy is 0.1394\n",
      "Lenet-5_model-2x117 saved!\n",
      "INFO: After 435 training iteration(s), loss is 2.92387, batch_train accuracy is 0.1445\n",
      "INFO: After 436 training iteration(s), loss is 2.92612, batch_train accuracy is 0.1602\n",
      "INFO: After 437 training iteration(s), loss is 2.93696, batch_train accuracy is 0.1387\n",
      "INFO: After 438 training iteration(s), loss is 2.92261, batch_train accuracy is 0.1523\n",
      "INFO: After 439 training iteration(s), loss is 2.93729, batch_train accuracy is 0.1504\n",
      "INFO: After 440 training iteration(s), loss is 2.94636, batch_train accuracy is 0.1367\n",
      "INFO: After 441 training iteration(s), loss is 2.92381, batch_train accuracy is 0.1621\n",
      "INFO: After 442 training iteration(s), loss is 2.92754, batch_train accuracy is 0.1719\n",
      "INFO: After 443 training iteration(s), loss is 2.92221, batch_train accuracy is 0.1660\n",
      "INFO: After 444 training iteration(s), loss is 2.92549, batch_train accuracy is 0.1973\n",
      "INFO: After 445 training iteration(s), loss is 2.92831, batch_train accuracy is 0.1602\n",
      "INFO: After 446 training iteration(s), loss is 2.92099, batch_train accuracy is 0.1465\n",
      "INFO: After 447 training iteration(s), loss is 2.93102, batch_train accuracy is 0.1387\n",
      "INFO: After 448 training iteration(s), loss is 2.91530, batch_train accuracy is 0.1738\n",
      "INFO: After 449 training iteration(s), loss is 2.92937, batch_train accuracy is 0.1367\n",
      "INFO: After 450 training iteration(s), loss is 2.92810, batch_train accuracy is 0.1406\n",
      "INFO: After 451 training iteration(s), loss is 2.92990, batch_train accuracy is 0.1699\n",
      "INFO: After 452 training iteration(s), loss is 2.92426, batch_train accuracy is 0.1621\n",
      "INFO: After 453 training iteration(s), loss is 2.92139, batch_train accuracy is 0.1777\n",
      "INFO: After 454 training iteration(s), loss is 2.93533, batch_train accuracy is 0.1465\n",
      "INFO: After 455 training iteration(s), loss is 2.93199, batch_train accuracy is 0.1406\n",
      "INFO: After 456 training iteration(s), loss is 2.93196, batch_train accuracy is 0.1367\n",
      "INFO: After 457 training iteration(s), loss is 2.92580, batch_train accuracy is 0.1426\n",
      "INFO: After 458 training iteration(s), loss is 2.92375, batch_train accuracy is 0.1719\n",
      "INFO: After 459 training iteration(s), loss is 2.93583, batch_train accuracy is 0.1680\n",
      "INFO: After 460 training iteration(s), loss is 2.91879, batch_train accuracy is 0.1504\n",
      "INFO: After 461 training iteration(s), loss is 2.93332, batch_train accuracy is 0.1309\n",
      "INFO: After 462 training iteration(s), loss is 2.93273, batch_train accuracy is 0.1426\n",
      "INFO: After 463 training iteration(s), loss is 2.92309, batch_train accuracy is 0.1465\n",
      "INFO: After 464 training iteration(s), loss is 2.92675, batch_train accuracy is 0.1562\n",
      "INFO: After 465 training iteration(s), loss is 2.91936, batch_train accuracy is 0.1543\n",
      "INFO: After 466 training iteration(s), loss is 2.93998, batch_train accuracy is 0.1367\n",
      "INFO: After 467 training iteration(s), loss is 2.92203, batch_train accuracy is 0.1641\n",
      "INFO: After 468 training iteration(s), loss is 2.93110, batch_train accuracy is 0.1660\n",
      "INFO: After 469 training iteration(s), loss is 2.92604, batch_train accuracy is 0.1406\n",
      "INFO: After 470 training iteration(s), loss is 2.92656, batch_train accuracy is 0.1562\n",
      "INFO: After 471 training iteration(s), loss is 2.92703, batch_train accuracy is 0.1504\n",
      "INFO: After 472 training iteration(s), loss is 2.93045, batch_train accuracy is 0.1523\n",
      "INFO: After 473 training iteration(s), loss is 2.92115, batch_train accuracy is 0.1230\n",
      "INFO: After 474 training iteration(s), loss is 2.92104, batch_train accuracy is 0.1562\n",
      "INFO: After 475 training iteration(s), loss is 2.94179, batch_train accuracy is 0.1504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: After 476 training iteration(s), loss is 2.92194, batch_train accuracy is 0.1543\n",
      "INFO: After 477 training iteration(s), loss is 2.91735, batch_train accuracy is 0.1738\n",
      "INFO: After 478 training iteration(s), loss is 2.92920, batch_train accuracy is 0.1230\n",
      "INFO: After 479 training iteration(s), loss is 2.91637, batch_train accuracy is 0.1699\n",
      "INFO: After 480 training iteration(s), loss is 2.92649, batch_train accuracy is 0.1504\n",
      "INFO: After 481 training iteration(s), loss is 2.91731, batch_train accuracy is 0.1582\n",
      "INFO: After 482 training iteration(s), loss is 2.92077, batch_train accuracy is 0.1738\n",
      "INFO: After 483 training iteration(s), loss is 2.91793, batch_train accuracy is 0.1660\n",
      "INFO: After 484 training iteration(s), loss is 2.92634, batch_train accuracy is 0.1543\n",
      "INFO: After 485 training iteration(s), loss is 2.92973, batch_train accuracy is 0.1660\n",
      "INFO: After 486 training iteration(s), loss is 2.93679, batch_train accuracy is 0.1543\n",
      "INFO: After 487 training iteration(s), loss is 2.93176, batch_train accuracy is 0.1191\n",
      "INFO: After 488 training iteration(s), loss is 2.92469, batch_train accuracy is 0.1543\n",
      "INFO: After 489 training iteration(s), loss is 2.92436, batch_train accuracy is 0.1602\n",
      "INFO: After 490 training iteration(s), loss is 2.93713, batch_train accuracy is 0.1230\n",
      "INFO: After 491 training iteration(s), loss is 2.91930, batch_train accuracy is 0.1660\n",
      "INFO: After 492 training iteration(s), loss is 2.93616, batch_train accuracy is 0.1211\n",
      "INFO: After 493 training iteration(s), loss is 2.91779, batch_train accuracy is 0.1406\n",
      "INFO: After 494 training iteration(s), loss is 2.91891, batch_train accuracy is 0.1523\n",
      "INFO: After 495 training iteration(s), loss is 2.91942, batch_train accuracy is 0.1719\n",
      "INFO: After 496 training iteration(s), loss is 2.92188, batch_train accuracy is 0.1484\n",
      "INFO: After 497 training iteration(s), loss is 2.92028, batch_train accuracy is 0.1348\n",
      "INFO: After 498 training iteration(s), loss is 2.91336, batch_train accuracy is 0.1875\n",
      "INFO: After 499 training iteration(s), loss is 2.92384, batch_train accuracy is 0.1484\n",
      "INFO: After 500 training iteration(s), loss is 2.90256, batch_train accuracy is 0.1797\n",
      "Lenet-5_model-500.ckpt saved!\n",
      "INFO: After 501 training iteration(s), loss is 2.91048, batch_train accuracy is 0.1621\n",
      "INFO: After 502 training iteration(s), loss is 2.92367, batch_train accuracy is 0.1504\n",
      "INFO: After 503 training iteration(s), loss is 2.92735, batch_train accuracy is 0.1328\n",
      "INFO: After 504 training iteration(s), loss is 2.91808, batch_train accuracy is 0.1680\n",
      "INFO: After 505 training iteration(s), loss is 2.93039, batch_train accuracy is 0.1562\n",
      "INFO: After 506 training iteration(s), loss is 2.91410, batch_train accuracy is 0.1484\n",
      "INFO: After 507 training iteration(s), loss is 2.91930, batch_train accuracy is 0.1699\n",
      "INFO: After 508 training iteration(s), loss is 2.91251, batch_train accuracy is 0.1660\n",
      "INFO: After 509 training iteration(s), loss is 2.90930, batch_train accuracy is 0.1445\n",
      "INFO: After 510 training iteration(s), loss is 2.91890, batch_train accuracy is 0.1758\n",
      "INFO: After 511 training iteration(s), loss is 2.91203, batch_train accuracy is 0.1562\n",
      "INFO: After 512 training iteration(s), loss is 2.93137, batch_train accuracy is 0.1387\n",
      "INFO: After 513 training iteration(s), loss is 2.92285, batch_train accuracy is 0.1504\n",
      "INFO: After 514 training iteration(s), loss is 2.91476, batch_train accuracy is 0.1367\n",
      "INFO: After 515 training iteration(s), loss is 2.91232, batch_train accuracy is 0.1289\n",
      "INFO: After 516 training iteration(s), loss is 2.91151, batch_train accuracy is 0.1641\n",
      "INFO: After 517 training iteration(s), loss is 2.92063, batch_train accuracy is 0.1113\n",
      "INFO: After 518 training iteration(s), loss is 2.91360, batch_train accuracy is 0.1855\n",
      "INFO: After 519 training iteration(s), loss is 2.92764, batch_train accuracy is 0.1172\n",
      "INFO: After 520 training iteration(s), loss is 2.92060, batch_train accuracy is 0.1426\n",
      "INFO: After 521 training iteration(s), loss is 2.92802, batch_train accuracy is 0.1621\n",
      "INFO: After 522 training iteration(s), loss is 2.91384, batch_train accuracy is 0.1699\n",
      "INFO: After 523 training iteration(s), loss is 2.91832, batch_train accuracy is 0.1562\n",
      "INFO: After 524 training iteration(s), loss is 2.92536, batch_train accuracy is 0.1484\n",
      "INFO: After 525 training iteration(s), loss is 2.91133, batch_train accuracy is 0.1777\n",
      "INFO: After 526 training iteration(s), loss is 2.91101, batch_train accuracy is 0.1699\n",
      "INFO: After 527 training iteration(s), loss is 2.91624, batch_train accuracy is 0.1855\n",
      "INFO: After 528 training iteration(s), loss is 2.92147, batch_train accuracy is 0.1914\n",
      "INFO: After 529 training iteration(s), loss is 2.91143, batch_train accuracy is 0.1836\n",
      "INFO: After 530 training iteration(s), loss is 2.91581, batch_train accuracy is 0.1621\n",
      "INFO: After 531 training iteration(s), loss is 2.91573, batch_train accuracy is 0.1562\n",
      "INFO: After 532 training iteration(s), loss is 2.92230, batch_train accuracy is 0.1719\n",
      "INFO: After 533 training iteration(s), loss is 2.91854, batch_train accuracy is 0.1562\n",
      "INFO: After 534 training iteration(s), loss is 2.91482, batch_train accuracy is 0.1445\n",
      "INFO: After 535 training iteration(s), loss is 2.92637, batch_train accuracy is 0.1621\n",
      "INFO: After 536 training iteration(s), loss is 2.90556, batch_train accuracy is 0.1895\n",
      "INFO: After 537 training iteration(s), loss is 2.91326, batch_train accuracy is 0.1699\n",
      "INFO: After 538 training iteration(s), loss is 2.90489, batch_train accuracy is 0.1699\n",
      "INFO: After 539 training iteration(s), loss is 2.91154, batch_train accuracy is 0.1836\n",
      "INFO: After 540 training iteration(s), loss is 2.91002, batch_train accuracy is 0.1875\n",
      "INFO: After 541 training iteration(s), loss is 2.91885, batch_train accuracy is 0.1191\n",
      "INFO: After 542 training iteration(s), loss is 2.90889, batch_train accuracy is 0.1777\n",
      "INFO: After 543 training iteration(s), loss is 2.92398, batch_train accuracy is 0.1504\n",
      "INFO: After 544 training iteration(s), loss is 2.91382, batch_train accuracy is 0.1699\n",
      "INFO: After 545 training iteration(s), loss is 2.90569, batch_train accuracy is 0.1836\n",
      "INFO: After 546 training iteration(s), loss is 2.91397, batch_train accuracy is 0.1680\n",
      "INFO: After 547 training iteration(s), loss is 2.90118, batch_train accuracy is 0.1504\n",
      "INFO: After 548 training iteration(s), loss is 2.91949, batch_train accuracy is 0.1719\n",
      "INFO: After 549 training iteration(s), loss is 2.92538, batch_train accuracy is 0.1543\n",
      "INFO: After 550 training iteration(s), loss is 2.91419, batch_train accuracy is 0.1562\n",
      "INFO: After 551 training iteration(s), loss is 2.91152, batch_train accuracy is 0.1582\n",
      "After 3 training epoch(s)(X117), loss is 2.92190, train accuracy is 0.1563\n",
      "Lenet-5_model-3x117 saved!\n",
      "INFO: After 552 training iteration(s), loss is 2.89932, batch_train accuracy is 0.1777\n",
      "INFO: After 553 training iteration(s), loss is 2.90927, batch_train accuracy is 0.1660\n",
      "INFO: After 554 training iteration(s), loss is 2.92199, batch_train accuracy is 0.1680\n",
      "INFO: After 555 training iteration(s), loss is 2.91018, batch_train accuracy is 0.1914\n",
      "INFO: After 556 training iteration(s), loss is 2.91587, batch_train accuracy is 0.1855\n",
      "INFO: After 557 training iteration(s), loss is 2.92380, batch_train accuracy is 0.1504\n",
      "INFO: After 558 training iteration(s), loss is 2.91493, batch_train accuracy is 0.1680\n",
      "INFO: After 559 training iteration(s), loss is 2.92451, batch_train accuracy is 0.1406\n",
      "INFO: After 560 training iteration(s), loss is 2.90358, batch_train accuracy is 0.1973\n",
      "INFO: After 561 training iteration(s), loss is 2.90988, batch_train accuracy is 0.1641\n",
      "INFO: After 562 training iteration(s), loss is 2.90933, batch_train accuracy is 0.1738\n",
      "INFO: After 563 training iteration(s), loss is 2.91118, batch_train accuracy is 0.1660\n",
      "INFO: After 564 training iteration(s), loss is 2.90744, batch_train accuracy is 0.1562\n",
      "INFO: After 565 training iteration(s), loss is 2.91333, batch_train accuracy is 0.1504\n",
      "INFO: After 566 training iteration(s), loss is 2.91634, batch_train accuracy is 0.1406\n",
      "INFO: After 567 training iteration(s), loss is 2.91379, batch_train accuracy is 0.1914\n",
      "INFO: After 568 training iteration(s), loss is 2.90924, batch_train accuracy is 0.1660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: After 569 training iteration(s), loss is 2.91927, batch_train accuracy is 0.1445\n",
      "INFO: After 570 training iteration(s), loss is 2.90414, batch_train accuracy is 0.1797\n",
      "INFO: After 571 training iteration(s), loss is 2.90192, batch_train accuracy is 0.1582\n",
      "INFO: After 572 training iteration(s), loss is 2.92109, batch_train accuracy is 0.1621\n",
      "INFO: After 573 training iteration(s), loss is 2.89958, batch_train accuracy is 0.1855\n",
      "INFO: After 574 training iteration(s), loss is 2.90131, batch_train accuracy is 0.1836\n",
      "INFO: After 575 training iteration(s), loss is 2.91384, batch_train accuracy is 0.1582\n",
      "INFO: After 576 training iteration(s), loss is 2.91368, batch_train accuracy is 0.1680\n",
      "INFO: After 577 training iteration(s), loss is 2.90933, batch_train accuracy is 0.1895\n",
      "INFO: After 578 training iteration(s), loss is 2.89977, batch_train accuracy is 0.2012\n",
      "INFO: After 579 training iteration(s), loss is 2.90729, batch_train accuracy is 0.1816\n",
      "INFO: After 580 training iteration(s), loss is 2.90796, batch_train accuracy is 0.1855\n",
      "INFO: After 581 training iteration(s), loss is 2.92134, batch_train accuracy is 0.1406\n",
      "INFO: After 582 training iteration(s), loss is 2.91013, batch_train accuracy is 0.1699\n",
      "INFO: After 583 training iteration(s), loss is 2.91258, batch_train accuracy is 0.1602\n",
      "INFO: After 584 training iteration(s), loss is 2.91812, batch_train accuracy is 0.1582\n",
      "INFO: After 585 training iteration(s), loss is 2.90235, batch_train accuracy is 0.1719\n",
      "INFO: After 586 training iteration(s), loss is 2.91379, batch_train accuracy is 0.1543\n",
      "INFO: After 587 training iteration(s), loss is 2.91041, batch_train accuracy is 0.1445\n",
      "INFO: After 588 training iteration(s), loss is 2.90202, batch_train accuracy is 0.1777\n",
      "INFO: After 589 training iteration(s), loss is 2.90464, batch_train accuracy is 0.1855\n",
      "INFO: After 590 training iteration(s), loss is 2.90980, batch_train accuracy is 0.1621\n",
      "INFO: After 591 training iteration(s), loss is 2.91953, batch_train accuracy is 0.1641\n",
      "INFO: After 592 training iteration(s), loss is 2.92291, batch_train accuracy is 0.1543\n",
      "INFO: After 593 training iteration(s), loss is 2.90555, batch_train accuracy is 0.1660\n",
      "INFO: After 594 training iteration(s), loss is 2.90792, batch_train accuracy is 0.1914\n",
      "INFO: After 595 training iteration(s), loss is 2.90742, batch_train accuracy is 0.1660\n",
      "INFO: After 596 training iteration(s), loss is 2.91219, batch_train accuracy is 0.1523\n",
      "INFO: After 597 training iteration(s), loss is 2.90225, batch_train accuracy is 0.1758\n",
      "INFO: After 598 training iteration(s), loss is 2.90668, batch_train accuracy is 0.1875\n",
      "INFO: After 599 training iteration(s), loss is 2.89856, batch_train accuracy is 0.1738\n",
      "INFO: After 600 training iteration(s), loss is 2.91212, batch_train accuracy is 0.1875\n",
      "Lenet-5_model-600.ckpt saved!\n",
      "INFO: After 601 training iteration(s), loss is 2.90649, batch_train accuracy is 0.1484\n",
      "INFO: After 602 training iteration(s), loss is 2.91191, batch_train accuracy is 0.1641\n",
      "INFO: After 603 training iteration(s), loss is 2.91537, batch_train accuracy is 0.1719\n",
      "INFO: After 604 training iteration(s), loss is 2.91358, batch_train accuracy is 0.1797\n",
      "INFO: After 605 training iteration(s), loss is 2.91466, batch_train accuracy is 0.1719\n",
      "INFO: After 606 training iteration(s), loss is 2.90885, batch_train accuracy is 0.1680\n",
      "INFO: After 607 training iteration(s), loss is 2.90716, batch_train accuracy is 0.1582\n",
      "INFO: After 608 training iteration(s), loss is 2.90945, batch_train accuracy is 0.1504\n",
      "INFO: After 609 training iteration(s), loss is 2.90877, batch_train accuracy is 0.1660\n",
      "INFO: After 610 training iteration(s), loss is 2.90539, batch_train accuracy is 0.1562\n",
      "INFO: After 611 training iteration(s), loss is 2.90938, batch_train accuracy is 0.1641\n",
      "INFO: After 612 training iteration(s), loss is 2.90170, batch_train accuracy is 0.1758\n",
      "INFO: After 613 training iteration(s), loss is 2.89615, batch_train accuracy is 0.2051\n",
      "INFO: After 614 training iteration(s), loss is 2.90722, batch_train accuracy is 0.1621\n",
      "INFO: After 615 training iteration(s), loss is 2.89771, batch_train accuracy is 0.1738\n",
      "INFO: After 616 training iteration(s), loss is 2.90033, batch_train accuracy is 0.1875\n",
      "INFO: After 617 training iteration(s), loss is 2.89551, batch_train accuracy is 0.1777\n",
      "INFO: After 618 training iteration(s), loss is 2.88194, batch_train accuracy is 0.2402\n",
      "INFO: After 619 training iteration(s), loss is 2.90449, batch_train accuracy is 0.1504\n",
      "INFO: After 620 training iteration(s), loss is 2.89622, batch_train accuracy is 0.2109\n",
      "INFO: After 621 training iteration(s), loss is 2.90067, batch_train accuracy is 0.1602\n",
      "INFO: After 622 training iteration(s), loss is 2.90706, batch_train accuracy is 0.1328\n",
      "INFO: After 623 training iteration(s), loss is 2.89376, batch_train accuracy is 0.1855\n",
      "INFO: After 624 training iteration(s), loss is 2.91735, batch_train accuracy is 0.1484\n",
      "INFO: After 625 training iteration(s), loss is 2.89496, batch_train accuracy is 0.2070\n",
      "INFO: After 626 training iteration(s), loss is 2.90876, batch_train accuracy is 0.1504\n",
      "INFO: After 627 training iteration(s), loss is 2.90307, batch_train accuracy is 0.1738\n",
      "INFO: After 628 training iteration(s), loss is 2.90617, batch_train accuracy is 0.1758\n",
      "INFO: After 629 training iteration(s), loss is 2.90711, batch_train accuracy is 0.1895\n",
      "INFO: After 630 training iteration(s), loss is 2.90399, batch_train accuracy is 0.1621\n",
      "INFO: After 631 training iteration(s), loss is 2.90092, batch_train accuracy is 0.1875\n",
      "INFO: After 632 training iteration(s), loss is 2.89554, batch_train accuracy is 0.1836\n",
      "INFO: After 633 training iteration(s), loss is 2.89716, batch_train accuracy is 0.1992\n",
      "INFO: After 634 training iteration(s), loss is 2.89717, batch_train accuracy is 0.1621\n",
      "INFO: After 635 training iteration(s), loss is 2.90517, batch_train accuracy is 0.1738\n",
      "INFO: After 636 training iteration(s), loss is 2.90165, batch_train accuracy is 0.1641\n",
      "INFO: After 637 training iteration(s), loss is 2.90736, batch_train accuracy is 0.1836\n",
      "INFO: After 638 training iteration(s), loss is 2.90561, batch_train accuracy is 0.1797\n",
      "INFO: After 639 training iteration(s), loss is 2.90640, batch_train accuracy is 0.1816\n",
      "INFO: After 640 training iteration(s), loss is 2.90051, batch_train accuracy is 0.1777\n",
      "INFO: After 641 training iteration(s), loss is 2.89249, batch_train accuracy is 0.1953\n",
      "INFO: After 642 training iteration(s), loss is 2.90004, batch_train accuracy is 0.1699\n",
      "INFO: After 643 training iteration(s), loss is 2.89364, batch_train accuracy is 0.1934\n",
      "INFO: After 644 training iteration(s), loss is 2.89144, batch_train accuracy is 0.1816\n",
      "INFO: After 645 training iteration(s), loss is 2.90223, batch_train accuracy is 0.1699\n",
      "INFO: After 646 training iteration(s), loss is 2.89705, batch_train accuracy is 0.1758\n",
      "INFO: After 647 training iteration(s), loss is 2.89025, batch_train accuracy is 0.1777\n",
      "INFO: After 648 training iteration(s), loss is 2.89955, batch_train accuracy is 0.1777\n",
      "INFO: After 649 training iteration(s), loss is 2.89801, batch_train accuracy is 0.1855\n",
      "INFO: After 650 training iteration(s), loss is 2.90005, batch_train accuracy is 0.1855\n",
      "INFO: After 651 training iteration(s), loss is 2.89986, batch_train accuracy is 0.1660\n",
      "INFO: After 652 training iteration(s), loss is 2.88742, batch_train accuracy is 0.2031\n",
      "INFO: After 653 training iteration(s), loss is 2.90705, batch_train accuracy is 0.1699\n",
      "INFO: After 654 training iteration(s), loss is 2.89061, batch_train accuracy is 0.1738\n",
      "INFO: After 655 training iteration(s), loss is 2.89988, batch_train accuracy is 0.2012\n",
      "INFO: After 656 training iteration(s), loss is 2.88458, batch_train accuracy is 0.1914\n",
      "INFO: After 657 training iteration(s), loss is 2.89929, batch_train accuracy is 0.1758\n",
      "INFO: After 658 training iteration(s), loss is 2.89239, batch_train accuracy is 0.2148\n",
      "INFO: After 659 training iteration(s), loss is 2.89545, batch_train accuracy is 0.2051\n",
      "INFO: After 660 training iteration(s), loss is 2.88463, batch_train accuracy is 0.1836\n",
      "INFO: After 661 training iteration(s), loss is 2.89747, batch_train accuracy is 0.1953\n",
      "INFO: After 662 training iteration(s), loss is 2.88347, batch_train accuracy is 0.2148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: After 663 training iteration(s), loss is 2.88410, batch_train accuracy is 0.2031\n",
      "INFO: After 664 training iteration(s), loss is 2.89546, batch_train accuracy is 0.1777\n",
      "INFO: After 665 training iteration(s), loss is 2.90176, batch_train accuracy is 0.1738\n",
      "INFO: After 666 training iteration(s), loss is 2.90137, batch_train accuracy is 0.1719\n",
      "INFO: After 667 training iteration(s), loss is 2.89268, batch_train accuracy is 0.1582\n",
      "INFO: After 668 training iteration(s), loss is 2.88867, batch_train accuracy is 0.1934\n",
      "After 4 training epoch(s)(X117), loss is 2.90442, train accuracy is 0.1747\n",
      "Lenet-5_model-4x117 saved!\n",
      "INFO: After 669 training iteration(s), loss is 2.89546, batch_train accuracy is 0.1992\n",
      "INFO: After 670 training iteration(s), loss is 2.89832, batch_train accuracy is 0.1855\n",
      "INFO: After 671 training iteration(s), loss is 2.89571, batch_train accuracy is 0.1699\n",
      "INFO: After 672 training iteration(s), loss is 2.88016, batch_train accuracy is 0.1914\n",
      "INFO: After 673 training iteration(s), loss is 2.88976, batch_train accuracy is 0.2227\n",
      "INFO: After 674 training iteration(s), loss is 2.89923, batch_train accuracy is 0.1523\n",
      "INFO: After 675 training iteration(s), loss is 2.90568, batch_train accuracy is 0.1504\n",
      "INFO: After 676 training iteration(s), loss is 2.88651, batch_train accuracy is 0.1816\n",
      "INFO: After 677 training iteration(s), loss is 2.88603, batch_train accuracy is 0.1855\n",
      "INFO: After 678 training iteration(s), loss is 2.89369, batch_train accuracy is 0.1914\n",
      "INFO: After 679 training iteration(s), loss is 2.89973, batch_train accuracy is 0.1797\n",
      "INFO: After 680 training iteration(s), loss is 2.88474, batch_train accuracy is 0.1973\n",
      "INFO: After 681 training iteration(s), loss is 2.89432, batch_train accuracy is 0.2012\n",
      "INFO: After 682 training iteration(s), loss is 2.88842, batch_train accuracy is 0.1992\n",
      "INFO: After 683 training iteration(s), loss is 2.89245, batch_train accuracy is 0.1914\n",
      "INFO: After 684 training iteration(s), loss is 2.88648, batch_train accuracy is 0.2188\n",
      "INFO: After 685 training iteration(s), loss is 2.89015, batch_train accuracy is 0.1621\n",
      "INFO: After 686 training iteration(s), loss is 2.89069, batch_train accuracy is 0.2188\n",
      "INFO: After 687 training iteration(s), loss is 2.88088, batch_train accuracy is 0.2012\n",
      "INFO: After 688 training iteration(s), loss is 2.88463, batch_train accuracy is 0.1836\n",
      "INFO: After 689 training iteration(s), loss is 2.89282, batch_train accuracy is 0.1797\n",
      "INFO: After 690 training iteration(s), loss is 2.88937, batch_train accuracy is 0.1973\n",
      "INFO: After 691 training iteration(s), loss is 2.89344, batch_train accuracy is 0.1602\n",
      "INFO: After 692 training iteration(s), loss is 2.88474, batch_train accuracy is 0.2227\n",
      "INFO: After 693 training iteration(s), loss is 2.88964, batch_train accuracy is 0.1934\n",
      "INFO: After 694 training iteration(s), loss is 2.87710, batch_train accuracy is 0.2227\n",
      "INFO: After 695 training iteration(s), loss is 2.87290, batch_train accuracy is 0.2305\n",
      "INFO: After 696 training iteration(s), loss is 2.87670, batch_train accuracy is 0.1992\n",
      "INFO: After 697 training iteration(s), loss is 2.88792, batch_train accuracy is 0.1875\n",
      "INFO: After 698 training iteration(s), loss is 2.90520, batch_train accuracy is 0.1816\n",
      "INFO: After 699 training iteration(s), loss is 2.88602, batch_train accuracy is 0.1914\n",
      "INFO: After 700 training iteration(s), loss is 2.90551, batch_train accuracy is 0.1641\n",
      "Lenet-5_model-700.ckpt saved!\n",
      "INFO: After 701 training iteration(s), loss is 2.88182, batch_train accuracy is 0.2207\n",
      "INFO: After 702 training iteration(s), loss is 2.89276, batch_train accuracy is 0.1914\n",
      "INFO: After 703 training iteration(s), loss is 2.89773, batch_train accuracy is 0.1992\n",
      "INFO: After 704 training iteration(s), loss is 2.88171, batch_train accuracy is 0.1973\n",
      "INFO: After 705 training iteration(s), loss is 2.89856, batch_train accuracy is 0.1660\n",
      "INFO: After 706 training iteration(s), loss is 2.87456, batch_train accuracy is 0.2051\n",
      "INFO: After 707 training iteration(s), loss is 2.88093, batch_train accuracy is 0.1992\n",
      "INFO: After 708 training iteration(s), loss is 2.89321, batch_train accuracy is 0.2051\n",
      "INFO: After 709 training iteration(s), loss is 2.89335, batch_train accuracy is 0.1836\n",
      "INFO: After 710 training iteration(s), loss is 2.88712, batch_train accuracy is 0.2051\n",
      "INFO: After 711 training iteration(s), loss is 2.87382, batch_train accuracy is 0.2109\n",
      "INFO: After 712 training iteration(s), loss is 2.88784, batch_train accuracy is 0.1777\n",
      "INFO: After 713 training iteration(s), loss is 2.87417, batch_train accuracy is 0.1797\n",
      "INFO: After 714 training iteration(s), loss is 2.88199, batch_train accuracy is 0.1914\n",
      "INFO: After 715 training iteration(s), loss is 2.89331, batch_train accuracy is 0.1777\n",
      "INFO: After 716 training iteration(s), loss is 2.88742, batch_train accuracy is 0.2012\n",
      "INFO: After 717 training iteration(s), loss is 2.89143, batch_train accuracy is 0.1875\n",
      "INFO: After 718 training iteration(s), loss is 2.88149, batch_train accuracy is 0.2148\n",
      "INFO: After 719 training iteration(s), loss is 2.89407, batch_train accuracy is 0.1797\n",
      "INFO: After 720 training iteration(s), loss is 2.90177, batch_train accuracy is 0.1836\n",
      "INFO: After 721 training iteration(s), loss is 2.89611, batch_train accuracy is 0.1719\n",
      "INFO: After 722 training iteration(s), loss is 2.89977, batch_train accuracy is 0.1758\n",
      "INFO: After 723 training iteration(s), loss is 2.88151, batch_train accuracy is 0.2051\n",
      "INFO: After 724 training iteration(s), loss is 2.87810, batch_train accuracy is 0.2363\n",
      "INFO: After 725 training iteration(s), loss is 2.88507, batch_train accuracy is 0.1836\n",
      "INFO: After 726 training iteration(s), loss is 2.87714, batch_train accuracy is 0.2285\n",
      "INFO: After 727 training iteration(s), loss is 2.86707, batch_train accuracy is 0.2246\n",
      "INFO: After 728 training iteration(s), loss is 2.88954, batch_train accuracy is 0.1777\n",
      "INFO: After 729 training iteration(s), loss is 2.88604, batch_train accuracy is 0.1992\n",
      "INFO: After 730 training iteration(s), loss is 2.88435, batch_train accuracy is 0.2090\n",
      "INFO: After 731 training iteration(s), loss is 2.86907, batch_train accuracy is 0.1953\n",
      "INFO: After 732 training iteration(s), loss is 2.87159, batch_train accuracy is 0.2031\n",
      "INFO: After 733 training iteration(s), loss is 2.87308, batch_train accuracy is 0.2148\n",
      "INFO: After 734 training iteration(s), loss is 2.87292, batch_train accuracy is 0.2285\n",
      "INFO: After 735 training iteration(s), loss is 2.86286, batch_train accuracy is 0.2344\n",
      "INFO: After 736 training iteration(s), loss is 2.87820, batch_train accuracy is 0.1973\n",
      "INFO: After 737 training iteration(s), loss is 2.89114, batch_train accuracy is 0.1875\n",
      "INFO: After 738 training iteration(s), loss is 2.87321, batch_train accuracy is 0.2324\n",
      "INFO: After 739 training iteration(s), loss is 2.87834, batch_train accuracy is 0.1855\n",
      "INFO: After 740 training iteration(s), loss is 2.87889, batch_train accuracy is 0.1934\n",
      "INFO: After 741 training iteration(s), loss is 2.87810, batch_train accuracy is 0.2188\n",
      "INFO: After 742 training iteration(s), loss is 2.88176, batch_train accuracy is 0.1855\n",
      "INFO: After 743 training iteration(s), loss is 2.86953, batch_train accuracy is 0.2090\n",
      "INFO: After 744 training iteration(s), loss is 2.87721, batch_train accuracy is 0.1934\n",
      "INFO: After 745 training iteration(s), loss is 2.87178, batch_train accuracy is 0.1914\n",
      "INFO: After 746 training iteration(s), loss is 2.88920, batch_train accuracy is 0.1953\n",
      "INFO: After 747 training iteration(s), loss is 2.87520, batch_train accuracy is 0.1953\n",
      "INFO: After 748 training iteration(s), loss is 2.88836, batch_train accuracy is 0.1562\n",
      "INFO: After 749 training iteration(s), loss is 2.85823, batch_train accuracy is 0.2207\n",
      "INFO: After 750 training iteration(s), loss is 2.88471, batch_train accuracy is 0.1992\n",
      "INFO: After 751 training iteration(s), loss is 2.86433, batch_train accuracy is 0.2324\n",
      "INFO: After 752 training iteration(s), loss is 2.87766, batch_train accuracy is 0.1953\n",
      "INFO: After 753 training iteration(s), loss is 2.90058, batch_train accuracy is 0.1758\n",
      "INFO: After 754 training iteration(s), loss is 2.88372, batch_train accuracy is 0.1816\n",
      "INFO: After 755 training iteration(s), loss is 2.87858, batch_train accuracy is 0.1777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: After 756 training iteration(s), loss is 2.86755, batch_train accuracy is 0.2188\n",
      "INFO: After 757 training iteration(s), loss is 2.89298, batch_train accuracy is 0.1973\n",
      "INFO: After 758 training iteration(s), loss is 2.86468, batch_train accuracy is 0.2480\n",
      "INFO: After 759 training iteration(s), loss is 2.87656, batch_train accuracy is 0.2266\n",
      "INFO: After 760 training iteration(s), loss is 2.87462, batch_train accuracy is 0.2129\n",
      "INFO: After 761 training iteration(s), loss is 2.87996, batch_train accuracy is 0.1914\n",
      "INFO: After 762 training iteration(s), loss is 2.86528, batch_train accuracy is 0.2285\n",
      "INFO: After 763 training iteration(s), loss is 2.87026, batch_train accuracy is 0.2090\n",
      "INFO: After 764 training iteration(s), loss is 2.86698, batch_train accuracy is 0.1953\n",
      "INFO: After 765 training iteration(s), loss is 2.86852, batch_train accuracy is 0.2227\n",
      "INFO: After 766 training iteration(s), loss is 2.87816, batch_train accuracy is 0.1992\n",
      "INFO: After 767 training iteration(s), loss is 2.87346, batch_train accuracy is 0.2090\n",
      "INFO: After 768 training iteration(s), loss is 2.87536, batch_train accuracy is 0.1836\n",
      "INFO: After 769 training iteration(s), loss is 2.86128, batch_train accuracy is 0.2344\n",
      "INFO: After 770 training iteration(s), loss is 2.87831, batch_train accuracy is 0.2070\n",
      "INFO: After 771 training iteration(s), loss is 2.87419, batch_train accuracy is 0.2207\n",
      "INFO: After 772 training iteration(s), loss is 2.86498, batch_train accuracy is 0.2207\n",
      "INFO: After 773 training iteration(s), loss is 2.84648, batch_train accuracy is 0.2500\n",
      "INFO: After 774 training iteration(s), loss is 2.89097, batch_train accuracy is 0.1934\n",
      "INFO: After 775 training iteration(s), loss is 2.87030, batch_train accuracy is 0.2168\n",
      "INFO: After 776 training iteration(s), loss is 2.85450, batch_train accuracy is 0.2090\n",
      "INFO: After 777 training iteration(s), loss is 2.86686, batch_train accuracy is 0.2344\n",
      "INFO: After 778 training iteration(s), loss is 2.85559, batch_train accuracy is 0.2090\n",
      "INFO: After 779 training iteration(s), loss is 2.86477, batch_train accuracy is 0.2285\n",
      "INFO: After 780 training iteration(s), loss is 2.86986, batch_train accuracy is 0.2109\n",
      "INFO: After 781 training iteration(s), loss is 2.86744, batch_train accuracy is 0.2129\n",
      "INFO: After 782 training iteration(s), loss is 2.86036, batch_train accuracy is 0.2227\n",
      "INFO: After 783 training iteration(s), loss is 2.87154, batch_train accuracy is 0.2109\n",
      "INFO: After 784 training iteration(s), loss is 2.87553, batch_train accuracy is 0.1973\n",
      "INFO: After 785 training iteration(s), loss is 2.86500, batch_train accuracy is 0.1992\n",
      "After 5 training epoch(s)(X117), loss is 2.88119, train accuracy is 0.2002\n",
      "Lenet-5_model-5x117 saved!\n",
      "INFO: After 786 training iteration(s), loss is 2.87033, batch_train accuracy is 0.2285\n",
      "INFO: After 787 training iteration(s), loss is 2.85624, batch_train accuracy is 0.2363\n",
      "INFO: After 788 training iteration(s), loss is 2.87008, batch_train accuracy is 0.1953\n",
      "INFO: After 789 training iteration(s), loss is 2.87339, batch_train accuracy is 0.2285\n",
      "INFO: After 790 training iteration(s), loss is 2.84536, batch_train accuracy is 0.2812\n",
      "INFO: After 791 training iteration(s), loss is 2.85817, batch_train accuracy is 0.2520\n",
      "INFO: After 792 training iteration(s), loss is 2.85831, batch_train accuracy is 0.2363\n",
      "INFO: After 793 training iteration(s), loss is 2.87769, batch_train accuracy is 0.2148\n",
      "INFO: After 794 training iteration(s), loss is 2.87037, batch_train accuracy is 0.2129\n",
      "INFO: After 795 training iteration(s), loss is 2.85986, batch_train accuracy is 0.2383\n",
      "INFO: After 796 training iteration(s), loss is 2.86085, batch_train accuracy is 0.2227\n",
      "INFO: After 797 training iteration(s), loss is 2.87339, batch_train accuracy is 0.2070\n",
      "INFO: After 798 training iteration(s), loss is 2.86155, batch_train accuracy is 0.2188\n",
      "INFO: After 799 training iteration(s), loss is 2.86255, batch_train accuracy is 0.2070\n",
      "INFO: After 800 training iteration(s), loss is 2.87684, batch_train accuracy is 0.1895\n",
      "Lenet-5_model-800.ckpt saved!\n",
      "INFO: After 801 training iteration(s), loss is 2.85399, batch_train accuracy is 0.2070\n",
      "INFO: After 802 training iteration(s), loss is 2.86753, batch_train accuracy is 0.1816\n",
      "INFO: After 803 training iteration(s), loss is 2.85453, batch_train accuracy is 0.2520\n",
      "INFO: After 804 training iteration(s), loss is 2.86541, batch_train accuracy is 0.2383\n",
      "INFO: After 805 training iteration(s), loss is 2.87526, batch_train accuracy is 0.2207\n",
      "INFO: After 806 training iteration(s), loss is 2.85998, batch_train accuracy is 0.2207\n",
      "INFO: After 807 training iteration(s), loss is 2.87066, batch_train accuracy is 0.2188\n",
      "INFO: After 808 training iteration(s), loss is 2.87447, batch_train accuracy is 0.2324\n",
      "INFO: After 809 training iteration(s), loss is 2.86296, batch_train accuracy is 0.2266\n",
      "INFO: After 810 training iteration(s), loss is 2.84766, batch_train accuracy is 0.2344\n",
      "INFO: After 811 training iteration(s), loss is 2.86497, batch_train accuracy is 0.2324\n",
      "INFO: After 812 training iteration(s), loss is 2.85395, batch_train accuracy is 0.2559\n",
      "INFO: After 813 training iteration(s), loss is 2.85464, batch_train accuracy is 0.2305\n",
      "INFO: After 814 training iteration(s), loss is 2.86913, batch_train accuracy is 0.2246\n",
      "INFO: After 815 training iteration(s), loss is 2.86730, batch_train accuracy is 0.2090\n",
      "INFO: After 816 training iteration(s), loss is 2.86751, batch_train accuracy is 0.2031\n",
      "INFO: After 817 training iteration(s), loss is 2.85572, batch_train accuracy is 0.2207\n",
      "INFO: After 818 training iteration(s), loss is 2.86476, batch_train accuracy is 0.2441\n",
      "INFO: After 819 training iteration(s), loss is 2.85646, batch_train accuracy is 0.2227\n",
      "INFO: After 820 training iteration(s), loss is 2.85845, batch_train accuracy is 0.2168\n",
      "INFO: After 821 training iteration(s), loss is 2.85804, batch_train accuracy is 0.1875\n",
      "INFO: After 822 training iteration(s), loss is 2.84729, batch_train accuracy is 0.2422\n",
      "INFO: After 823 training iteration(s), loss is 2.86020, batch_train accuracy is 0.2363\n",
      "INFO: After 824 training iteration(s), loss is 2.84983, batch_train accuracy is 0.2266\n",
      "INFO: After 825 training iteration(s), loss is 2.85131, batch_train accuracy is 0.2129\n",
      "INFO: After 826 training iteration(s), loss is 2.86939, batch_train accuracy is 0.2051\n",
      "INFO: After 827 training iteration(s), loss is 2.87038, batch_train accuracy is 0.2129\n",
      "INFO: After 828 training iteration(s), loss is 2.84458, batch_train accuracy is 0.2500\n",
      "INFO: After 829 training iteration(s), loss is 2.86218, batch_train accuracy is 0.1953\n",
      "INFO: After 830 training iteration(s), loss is 2.86747, batch_train accuracy is 0.2266\n",
      "INFO: After 831 training iteration(s), loss is 2.86528, batch_train accuracy is 0.2500\n",
      "INFO: After 832 training iteration(s), loss is 2.86133, batch_train accuracy is 0.2090\n",
      "INFO: After 833 training iteration(s), loss is 2.84302, batch_train accuracy is 0.2715\n",
      "INFO: After 834 training iteration(s), loss is 2.85871, batch_train accuracy is 0.2383\n",
      "INFO: After 835 training iteration(s), loss is 2.88461, batch_train accuracy is 0.1992\n",
      "INFO: After 836 training iteration(s), loss is 2.85196, batch_train accuracy is 0.2285\n",
      "INFO: After 837 training iteration(s), loss is 2.85920, batch_train accuracy is 0.2246\n",
      "INFO: After 838 training iteration(s), loss is 2.89684, batch_train accuracy is 0.1758\n",
      "INFO: After 839 training iteration(s), loss is 2.86126, batch_train accuracy is 0.2441\n",
      "INFO: After 840 training iteration(s), loss is 2.84198, batch_train accuracy is 0.2520\n",
      "INFO: After 841 training iteration(s), loss is 2.86774, batch_train accuracy is 0.2129\n",
      "INFO: After 842 training iteration(s), loss is 2.85998, batch_train accuracy is 0.2383\n",
      "INFO: After 843 training iteration(s), loss is 2.84341, batch_train accuracy is 0.2559\n",
      "INFO: After 844 training iteration(s), loss is 2.86127, batch_train accuracy is 0.2090\n",
      "INFO: After 845 training iteration(s), loss is 2.86421, batch_train accuracy is 0.2148\n",
      "INFO: After 846 training iteration(s), loss is 2.85041, batch_train accuracy is 0.2441\n",
      "INFO: After 847 training iteration(s), loss is 2.84060, batch_train accuracy is 0.2480\n",
      "INFO: After 848 training iteration(s), loss is 2.85024, batch_train accuracy is 0.2461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: After 849 training iteration(s), loss is 2.83589, batch_train accuracy is 0.2441\n",
      "INFO: After 850 training iteration(s), loss is 2.86245, batch_train accuracy is 0.2148\n",
      "INFO: After 851 training iteration(s), loss is 2.83984, batch_train accuracy is 0.2773\n",
      "INFO: After 852 training iteration(s), loss is 2.85042, batch_train accuracy is 0.2285\n",
      "INFO: After 853 training iteration(s), loss is 2.83873, batch_train accuracy is 0.2559\n",
      "INFO: After 854 training iteration(s), loss is 2.85087, batch_train accuracy is 0.2070\n",
      "INFO: After 855 training iteration(s), loss is 2.84266, batch_train accuracy is 0.2598\n",
      "INFO: After 856 training iteration(s), loss is 2.84791, batch_train accuracy is 0.2363\n",
      "INFO: After 857 training iteration(s), loss is 2.84389, batch_train accuracy is 0.2207\n",
      "INFO: After 858 training iteration(s), loss is 2.82431, batch_train accuracy is 0.2852\n",
      "INFO: After 859 training iteration(s), loss is 2.83929, batch_train accuracy is 0.2715\n",
      "INFO: After 860 training iteration(s), loss is 2.86179, batch_train accuracy is 0.2109\n",
      "INFO: After 861 training iteration(s), loss is 2.86236, batch_train accuracy is 0.2266\n",
      "INFO: After 862 training iteration(s), loss is 2.85704, batch_train accuracy is 0.2480\n",
      "INFO: After 863 training iteration(s), loss is 2.86379, batch_train accuracy is 0.2344\n",
      "INFO: After 864 training iteration(s), loss is 2.83563, batch_train accuracy is 0.2637\n",
      "INFO: After 865 training iteration(s), loss is 2.84550, batch_train accuracy is 0.2285\n",
      "INFO: After 866 training iteration(s), loss is 2.84042, batch_train accuracy is 0.2422\n",
      "INFO: After 867 training iteration(s), loss is 2.82844, batch_train accuracy is 0.2441\n",
      "INFO: After 868 training iteration(s), loss is 2.85151, batch_train accuracy is 0.2207\n",
      "INFO: After 869 training iteration(s), loss is 2.82782, batch_train accuracy is 0.2695\n",
      "INFO: After 870 training iteration(s), loss is 2.85894, batch_train accuracy is 0.2129\n",
      "INFO: After 871 training iteration(s), loss is 2.85831, batch_train accuracy is 0.2285\n",
      "INFO: After 872 training iteration(s), loss is 2.86560, batch_train accuracy is 0.2324\n",
      "INFO: After 873 training iteration(s), loss is 2.83923, batch_train accuracy is 0.2617\n",
      "INFO: After 874 training iteration(s), loss is 2.84943, batch_train accuracy is 0.2402\n",
      "INFO: After 875 training iteration(s), loss is 2.85807, batch_train accuracy is 0.2480\n",
      "INFO: After 876 training iteration(s), loss is 2.83706, batch_train accuracy is 0.2617\n",
      "INFO: After 877 training iteration(s), loss is 2.84397, batch_train accuracy is 0.2363\n",
      "INFO: After 878 training iteration(s), loss is 2.83108, batch_train accuracy is 0.2480\n",
      "INFO: After 879 training iteration(s), loss is 2.83018, batch_train accuracy is 0.2188\n",
      "INFO: After 880 training iteration(s), loss is 2.85499, batch_train accuracy is 0.2246\n",
      "INFO: After 881 training iteration(s), loss is 2.82332, batch_train accuracy is 0.2949\n",
      "INFO: After 882 training iteration(s), loss is 2.83008, batch_train accuracy is 0.2598\n",
      "INFO: After 883 training iteration(s), loss is 2.84493, batch_train accuracy is 0.2422\n",
      "INFO: After 884 training iteration(s), loss is 2.85190, batch_train accuracy is 0.2129\n",
      "INFO: After 885 training iteration(s), loss is 2.84589, batch_train accuracy is 0.2363\n",
      "INFO: After 886 training iteration(s), loss is 2.84607, batch_train accuracy is 0.2305\n",
      "INFO: After 887 training iteration(s), loss is 2.83326, batch_train accuracy is 0.2734\n",
      "INFO: After 888 training iteration(s), loss is 2.83932, batch_train accuracy is 0.2480\n",
      "INFO: After 889 training iteration(s), loss is 2.83390, batch_train accuracy is 0.2715\n",
      "INFO: After 890 training iteration(s), loss is 2.81936, batch_train accuracy is 0.2637\n",
      "INFO: After 891 training iteration(s), loss is 2.83467, batch_train accuracy is 0.2559\n",
      "INFO: After 892 training iteration(s), loss is 2.83128, batch_train accuracy is 0.2656\n",
      "INFO: After 893 training iteration(s), loss is 2.82831, batch_train accuracy is 0.2539\n",
      "INFO: After 894 training iteration(s), loss is 2.82983, batch_train accuracy is 0.2715\n",
      "INFO: After 895 training iteration(s), loss is 2.83726, batch_train accuracy is 0.2324\n",
      "INFO: After 896 training iteration(s), loss is 2.82679, batch_train accuracy is 0.2246\n",
      "INFO: After 897 training iteration(s), loss is 2.81174, batch_train accuracy is 0.2715\n",
      "INFO: After 898 training iteration(s), loss is 2.81517, batch_train accuracy is 0.2559\n",
      "INFO: After 899 training iteration(s), loss is 2.83075, batch_train accuracy is 0.2578\n",
      "INFO: After 900 training iteration(s), loss is 2.83404, batch_train accuracy is 0.2246\n",
      "Lenet-5_model-900.ckpt saved!\n",
      "INFO: After 901 training iteration(s), loss is 2.83568, batch_train accuracy is 0.2402\n",
      "INFO: After 902 training iteration(s), loss is 2.84427, batch_train accuracy is 0.2461\n",
      "After 6 training epoch(s)(X117), loss is 2.85187, train accuracy is 0.2347\n",
      "Lenet-5_model-6x117 saved!\n",
      "INFO: After 903 training iteration(s), loss is 2.83490, batch_train accuracy is 0.2617\n",
      "INFO: After 904 training iteration(s), loss is 2.83038, batch_train accuracy is 0.2539\n",
      "INFO: After 905 training iteration(s), loss is 2.83264, batch_train accuracy is 0.2441\n",
      "INFO: After 906 training iteration(s), loss is 2.82279, batch_train accuracy is 0.2773\n",
      "INFO: After 907 training iteration(s), loss is 2.82058, batch_train accuracy is 0.2930\n",
      "INFO: After 908 training iteration(s), loss is 2.83437, batch_train accuracy is 0.2734\n",
      "INFO: After 909 training iteration(s), loss is 2.84776, batch_train accuracy is 0.2539\n",
      "INFO: After 910 training iteration(s), loss is 2.81975, batch_train accuracy is 0.2676\n",
      "INFO: After 911 training iteration(s), loss is 2.83666, batch_train accuracy is 0.2598\n",
      "INFO: After 912 training iteration(s), loss is 2.82190, batch_train accuracy is 0.2656\n",
      "INFO: After 913 training iteration(s), loss is 2.83084, batch_train accuracy is 0.2598\n",
      "INFO: After 914 training iteration(s), loss is 2.82401, batch_train accuracy is 0.2617\n",
      "INFO: After 915 training iteration(s), loss is 2.82355, batch_train accuracy is 0.2676\n",
      "INFO: After 916 training iteration(s), loss is 2.84924, batch_train accuracy is 0.2344\n",
      "INFO: After 917 training iteration(s), loss is 2.81917, batch_train accuracy is 0.2480\n",
      "INFO: After 918 training iteration(s), loss is 2.82761, batch_train accuracy is 0.2871\n",
      "INFO: After 919 training iteration(s), loss is 2.82660, batch_train accuracy is 0.2500\n",
      "INFO: After 920 training iteration(s), loss is 2.82936, batch_train accuracy is 0.2539\n",
      "INFO: After 921 training iteration(s), loss is 2.82426, batch_train accuracy is 0.2363\n",
      "INFO: After 922 training iteration(s), loss is 2.81624, batch_train accuracy is 0.2754\n",
      "INFO: After 923 training iteration(s), loss is 2.82872, batch_train accuracy is 0.2715\n",
      "INFO: After 924 training iteration(s), loss is 2.83843, batch_train accuracy is 0.2520\n",
      "INFO: After 925 training iteration(s), loss is 2.82808, batch_train accuracy is 0.3086\n",
      "INFO: After 926 training iteration(s), loss is 2.81754, batch_train accuracy is 0.2715\n",
      "INFO: After 927 training iteration(s), loss is 2.83235, batch_train accuracy is 0.2539\n",
      "INFO: After 928 training iteration(s), loss is 2.83280, batch_train accuracy is 0.2617\n",
      "INFO: After 929 training iteration(s), loss is 2.81641, batch_train accuracy is 0.2832\n",
      "INFO: After 930 training iteration(s), loss is 2.80240, batch_train accuracy is 0.2852\n",
      "INFO: After 931 training iteration(s), loss is 2.81527, batch_train accuracy is 0.2715\n",
      "INFO: After 932 training iteration(s), loss is 2.82807, batch_train accuracy is 0.2559\n",
      "INFO: After 933 training iteration(s), loss is 2.82039, batch_train accuracy is 0.2676\n",
      "INFO: After 934 training iteration(s), loss is 2.82848, batch_train accuracy is 0.2324\n",
      "INFO: After 935 training iteration(s), loss is 2.81524, batch_train accuracy is 0.2559\n",
      "INFO: After 936 training iteration(s), loss is 2.81919, batch_train accuracy is 0.2715\n",
      "INFO: After 937 training iteration(s), loss is 2.83410, batch_train accuracy is 0.2539\n",
      "INFO: After 938 training iteration(s), loss is 2.82280, batch_train accuracy is 0.2598\n",
      "INFO: After 939 training iteration(s), loss is 2.80911, batch_train accuracy is 0.2598\n",
      "INFO: After 940 training iteration(s), loss is 2.81285, batch_train accuracy is 0.2676\n",
      "INFO: After 941 training iteration(s), loss is 2.79985, batch_train accuracy is 0.2793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: After 942 training iteration(s), loss is 2.83737, batch_train accuracy is 0.2578\n",
      "INFO: After 943 training iteration(s), loss is 2.82790, batch_train accuracy is 0.2480\n",
      "INFO: After 944 training iteration(s), loss is 2.82518, batch_train accuracy is 0.2852\n",
      "INFO: After 945 training iteration(s), loss is 2.82243, batch_train accuracy is 0.2852\n",
      "INFO: After 946 training iteration(s), loss is 2.82140, batch_train accuracy is 0.2637\n",
      "INFO: After 947 training iteration(s), loss is 2.82164, batch_train accuracy is 0.2734\n",
      "INFO: After 948 training iteration(s), loss is 2.80044, batch_train accuracy is 0.2949\n",
      "INFO: After 949 training iteration(s), loss is 2.82074, batch_train accuracy is 0.2598\n",
      "INFO: After 950 training iteration(s), loss is 2.80882, batch_train accuracy is 0.2676\n",
      "INFO: After 951 training iteration(s), loss is 2.82297, batch_train accuracy is 0.2695\n",
      "INFO: After 952 training iteration(s), loss is 2.81511, batch_train accuracy is 0.2598\n",
      "INFO: After 953 training iteration(s), loss is 2.82391, batch_train accuracy is 0.2793\n",
      "INFO: After 954 training iteration(s), loss is 2.83453, batch_train accuracy is 0.2324\n",
      "INFO: After 955 training iteration(s), loss is 2.82938, batch_train accuracy is 0.2578\n",
      "INFO: After 956 training iteration(s), loss is 2.82208, batch_train accuracy is 0.2754\n",
      "INFO: After 957 training iteration(s), loss is 2.82665, batch_train accuracy is 0.2402\n",
      "INFO: After 958 training iteration(s), loss is 2.81942, batch_train accuracy is 0.2695\n",
      "INFO: After 959 training iteration(s), loss is 2.82565, batch_train accuracy is 0.2559\n",
      "INFO: After 960 training iteration(s), loss is 2.80388, batch_train accuracy is 0.2773\n",
      "INFO: After 961 training iteration(s), loss is 2.83157, batch_train accuracy is 0.2461\n",
      "INFO: After 962 training iteration(s), loss is 2.82425, batch_train accuracy is 0.2598\n",
      "INFO: After 963 training iteration(s), loss is 2.79257, batch_train accuracy is 0.2578\n",
      "INFO: After 964 training iteration(s), loss is 2.81134, batch_train accuracy is 0.2715\n",
      "INFO: After 965 training iteration(s), loss is 2.81924, batch_train accuracy is 0.2539\n",
      "INFO: After 966 training iteration(s), loss is 2.79804, batch_train accuracy is 0.3027\n",
      "INFO: After 967 training iteration(s), loss is 2.79532, batch_train accuracy is 0.3086\n",
      "INFO: After 968 training iteration(s), loss is 2.79428, batch_train accuracy is 0.2832\n",
      "INFO: After 969 training iteration(s), loss is 2.81178, batch_train accuracy is 0.2793\n",
      "INFO: After 970 training iteration(s), loss is 2.79346, batch_train accuracy is 0.2578\n",
      "INFO: After 971 training iteration(s), loss is 2.82332, batch_train accuracy is 0.2695\n",
      "INFO: After 972 training iteration(s), loss is 2.80144, batch_train accuracy is 0.2832\n",
      "INFO: After 973 training iteration(s), loss is 2.80634, batch_train accuracy is 0.2695\n",
      "INFO: After 974 training iteration(s), loss is 2.79151, batch_train accuracy is 0.3203\n",
      "INFO: After 975 training iteration(s), loss is 2.79484, batch_train accuracy is 0.2988\n",
      "INFO: After 976 training iteration(s), loss is 2.78999, batch_train accuracy is 0.2949\n",
      "INFO: After 977 training iteration(s), loss is 2.81538, batch_train accuracy is 0.2930\n",
      "INFO: After 978 training iteration(s), loss is 2.78231, batch_train accuracy is 0.3047\n",
      "INFO: After 979 training iteration(s), loss is 2.79617, batch_train accuracy is 0.2734\n",
      "INFO: After 980 training iteration(s), loss is 2.82351, batch_train accuracy is 0.2715\n",
      "INFO: After 981 training iteration(s), loss is 2.81551, batch_train accuracy is 0.2656\n",
      "INFO: After 982 training iteration(s), loss is 2.80723, batch_train accuracy is 0.2715\n",
      "INFO: After 983 training iteration(s), loss is 2.80003, batch_train accuracy is 0.2812\n",
      "INFO: After 984 training iteration(s), loss is 2.80852, batch_train accuracy is 0.2676\n",
      "INFO: After 985 training iteration(s), loss is 2.77506, batch_train accuracy is 0.3145\n",
      "INFO: After 986 training iteration(s), loss is 2.80563, batch_train accuracy is 0.2559\n",
      "INFO: After 987 training iteration(s), loss is 2.82293, batch_train accuracy is 0.2617\n",
      "INFO: After 988 training iteration(s), loss is 2.80333, batch_train accuracy is 0.2754\n",
      "INFO: After 989 training iteration(s), loss is 2.81980, batch_train accuracy is 0.2383\n",
      "INFO: After 990 training iteration(s), loss is 2.79653, batch_train accuracy is 0.2812\n",
      "INFO: After 991 training iteration(s), loss is 2.79601, batch_train accuracy is 0.2715\n",
      "INFO: After 992 training iteration(s), loss is 2.81677, batch_train accuracy is 0.2695\n",
      "INFO: After 993 training iteration(s), loss is 2.80048, batch_train accuracy is 0.3105\n",
      "INFO: After 994 training iteration(s), loss is 2.79166, batch_train accuracy is 0.2910\n",
      "INFO: After 995 training iteration(s), loss is 2.79512, batch_train accuracy is 0.3086\n",
      "INFO: After 996 training iteration(s), loss is 2.79369, batch_train accuracy is 0.2969\n",
      "INFO: After 997 training iteration(s), loss is 2.80777, batch_train accuracy is 0.2715\n",
      "INFO: After 998 training iteration(s), loss is 2.78497, batch_train accuracy is 0.2793\n",
      "INFO: After 999 training iteration(s), loss is 2.79039, batch_train accuracy is 0.2793\n",
      "INFO: After 1000 training iteration(s), loss is 2.79007, batch_train accuracy is 0.2930\n",
      "Lenet-5_model-1000.ckpt saved!\n",
      "INFO: After 1001 training iteration(s), loss is 2.78993, batch_train accuracy is 0.2988\n",
      "INFO: After 1002 training iteration(s), loss is 2.81087, batch_train accuracy is 0.2832\n",
      "INFO: After 1003 training iteration(s), loss is 2.79249, batch_train accuracy is 0.2617\n",
      "INFO: After 1004 training iteration(s), loss is 2.79809, batch_train accuracy is 0.3008\n",
      "INFO: After 1005 training iteration(s), loss is 2.76870, batch_train accuracy is 0.3320\n",
      "INFO: After 1006 training iteration(s), loss is 2.81039, batch_train accuracy is 0.2930\n",
      "INFO: After 1007 training iteration(s), loss is 2.78288, batch_train accuracy is 0.3184\n",
      "INFO: After 1008 training iteration(s), loss is 2.78227, batch_train accuracy is 0.3203\n",
      "INFO: After 1009 training iteration(s), loss is 2.78664, batch_train accuracy is 0.2871\n",
      "INFO: After 1010 training iteration(s), loss is 2.79587, batch_train accuracy is 0.2891\n",
      "INFO: After 1011 training iteration(s), loss is 2.76883, batch_train accuracy is 0.3125\n",
      "INFO: After 1012 training iteration(s), loss is 2.78257, batch_train accuracy is 0.3105\n",
      "INFO: After 1013 training iteration(s), loss is 2.77875, batch_train accuracy is 0.3066\n",
      "INFO: After 1014 training iteration(s), loss is 2.79981, batch_train accuracy is 0.2891\n",
      "INFO: After 1015 training iteration(s), loss is 2.77766, batch_train accuracy is 0.3086\n",
      "INFO: After 1016 training iteration(s), loss is 2.78792, batch_train accuracy is 0.2949\n",
      "INFO: After 1017 training iteration(s), loss is 2.80653, batch_train accuracy is 0.2812\n",
      "INFO: After 1018 training iteration(s), loss is 2.78794, batch_train accuracy is 0.3047\n",
      "INFO: After 1019 training iteration(s), loss is 2.77445, batch_train accuracy is 0.3105\n",
      "After 7 training epoch(s)(X117), loss is 2.81098, train accuracy is 0.2754\n",
      "Lenet-5_model-7x117 saved!\n",
      "INFO: After 1020 training iteration(s), loss is 2.78061, batch_train accuracy is 0.3008\n",
      "INFO: After 1021 training iteration(s), loss is 2.79482, batch_train accuracy is 0.3047\n",
      "INFO: After 1022 training iteration(s), loss is 2.79846, batch_train accuracy is 0.2695\n",
      "INFO: After 1023 training iteration(s), loss is 2.77107, batch_train accuracy is 0.3223\n",
      "INFO: After 1024 training iteration(s), loss is 2.78111, batch_train accuracy is 0.3066\n",
      "INFO: After 1025 training iteration(s), loss is 2.77504, batch_train accuracy is 0.3066\n",
      "INFO: After 1026 training iteration(s), loss is 2.78388, batch_train accuracy is 0.3008\n",
      "INFO: After 1027 training iteration(s), loss is 2.77865, batch_train accuracy is 0.2988\n",
      "INFO: After 1028 training iteration(s), loss is 2.76981, batch_train accuracy is 0.3125\n",
      "INFO: After 1029 training iteration(s), loss is 2.79318, batch_train accuracy is 0.3203\n",
      "INFO: After 1030 training iteration(s), loss is 2.76853, batch_train accuracy is 0.3047\n",
      "INFO: After 1031 training iteration(s), loss is 2.77035, batch_train accuracy is 0.2949\n",
      "INFO: After 1032 training iteration(s), loss is 2.77526, batch_train accuracy is 0.3086\n",
      "INFO: After 1033 training iteration(s), loss is 2.80080, batch_train accuracy is 0.2578\n",
      "INFO: After 1034 training iteration(s), loss is 2.77025, batch_train accuracy is 0.3203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: After 1035 training iteration(s), loss is 2.77924, batch_train accuracy is 0.3027\n",
      "INFO: After 1036 training iteration(s), loss is 2.77807, batch_train accuracy is 0.3027\n",
      "INFO: After 1037 training iteration(s), loss is 2.75806, batch_train accuracy is 0.3516\n",
      "INFO: After 1038 training iteration(s), loss is 2.76710, batch_train accuracy is 0.3125\n",
      "INFO: After 1039 training iteration(s), loss is 2.77420, batch_train accuracy is 0.3184\n",
      "INFO: After 1040 training iteration(s), loss is 2.79220, batch_train accuracy is 0.2793\n",
      "INFO: After 1041 training iteration(s), loss is 2.78216, batch_train accuracy is 0.3008\n",
      "INFO: After 1042 training iteration(s), loss is 2.75549, batch_train accuracy is 0.3027\n",
      "INFO: After 1043 training iteration(s), loss is 2.78065, batch_train accuracy is 0.3145\n",
      "INFO: After 1044 training iteration(s), loss is 2.78219, batch_train accuracy is 0.3066\n",
      "INFO: After 1045 training iteration(s), loss is 2.77622, batch_train accuracy is 0.2910\n",
      "INFO: After 1046 training iteration(s), loss is 2.77582, batch_train accuracy is 0.3105\n",
      "INFO: After 1047 training iteration(s), loss is 2.77626, batch_train accuracy is 0.3008\n",
      "INFO: After 1048 training iteration(s), loss is 2.77196, batch_train accuracy is 0.3008\n",
      "INFO: After 1049 training iteration(s), loss is 2.77997, batch_train accuracy is 0.3008\n",
      "INFO: After 1050 training iteration(s), loss is 2.77655, batch_train accuracy is 0.3145\n",
      "INFO: After 1051 training iteration(s), loss is 2.77710, batch_train accuracy is 0.2852\n",
      "INFO: After 1052 training iteration(s), loss is 2.78760, batch_train accuracy is 0.2910\n",
      "INFO: After 1053 training iteration(s), loss is 2.78770, batch_train accuracy is 0.2656\n",
      "INFO: After 1054 training iteration(s), loss is 2.78782, batch_train accuracy is 0.2715\n",
      "INFO: After 1055 training iteration(s), loss is 2.76754, batch_train accuracy is 0.3242\n",
      "INFO: After 1056 training iteration(s), loss is 2.76609, batch_train accuracy is 0.2910\n",
      "INFO: After 1057 training iteration(s), loss is 2.76260, batch_train accuracy is 0.3262\n",
      "INFO: After 1058 training iteration(s), loss is 2.75059, batch_train accuracy is 0.3184\n",
      "INFO: After 1059 training iteration(s), loss is 2.77715, batch_train accuracy is 0.3066\n",
      "INFO: After 1060 training iteration(s), loss is 2.79134, batch_train accuracy is 0.2930\n",
      "INFO: After 1061 training iteration(s), loss is 2.78407, batch_train accuracy is 0.2969\n",
      "INFO: After 1062 training iteration(s), loss is 2.77424, batch_train accuracy is 0.3223\n",
      "INFO: After 1063 training iteration(s), loss is 2.75678, batch_train accuracy is 0.3086\n",
      "INFO: After 1064 training iteration(s), loss is 2.76205, batch_train accuracy is 0.2988\n",
      "INFO: After 1065 training iteration(s), loss is 2.74816, batch_train accuracy is 0.3477\n",
      "INFO: After 1066 training iteration(s), loss is 2.76517, batch_train accuracy is 0.2930\n",
      "INFO: After 1067 training iteration(s), loss is 2.78789, batch_train accuracy is 0.3203\n",
      "INFO: After 1068 training iteration(s), loss is 2.76673, batch_train accuracy is 0.2969\n",
      "INFO: After 1069 training iteration(s), loss is 2.76647, batch_train accuracy is 0.3398\n",
      "INFO: After 1070 training iteration(s), loss is 2.78359, batch_train accuracy is 0.2910\n",
      "INFO: After 1071 training iteration(s), loss is 2.77578, batch_train accuracy is 0.3145\n",
      "INFO: After 1072 training iteration(s), loss is 2.78277, batch_train accuracy is 0.2910\n",
      "INFO: After 1073 training iteration(s), loss is 2.79713, batch_train accuracy is 0.2891\n",
      "INFO: After 1074 training iteration(s), loss is 2.74609, batch_train accuracy is 0.3535\n",
      "INFO: After 1075 training iteration(s), loss is 2.76852, batch_train accuracy is 0.3066\n",
      "INFO: After 1076 training iteration(s), loss is 2.79303, batch_train accuracy is 0.2695\n",
      "INFO: After 1077 training iteration(s), loss is 2.73873, batch_train accuracy is 0.3594\n",
      "INFO: After 1078 training iteration(s), loss is 2.77404, batch_train accuracy is 0.3066\n",
      "INFO: After 1079 training iteration(s), loss is 2.75936, batch_train accuracy is 0.3184\n",
      "INFO: After 1080 training iteration(s), loss is 2.76385, batch_train accuracy is 0.3223\n",
      "INFO: After 1081 training iteration(s), loss is 2.77868, batch_train accuracy is 0.3008\n",
      "INFO: After 1082 training iteration(s), loss is 2.74836, batch_train accuracy is 0.3340\n",
      "INFO: After 1083 training iteration(s), loss is 2.72718, batch_train accuracy is 0.3594\n",
      "INFO: After 1084 training iteration(s), loss is 2.74036, batch_train accuracy is 0.3789\n",
      "INFO: After 1085 training iteration(s), loss is 2.74333, batch_train accuracy is 0.3633\n",
      "INFO: After 1086 training iteration(s), loss is 2.74055, batch_train accuracy is 0.3301\n",
      "INFO: After 1087 training iteration(s), loss is 2.75436, batch_train accuracy is 0.2969\n",
      "INFO: After 1088 training iteration(s), loss is 2.75157, batch_train accuracy is 0.2969\n",
      "INFO: After 1089 training iteration(s), loss is 2.74384, batch_train accuracy is 0.3359\n",
      "INFO: After 1090 training iteration(s), loss is 2.73523, batch_train accuracy is 0.3242\n",
      "INFO: After 1091 training iteration(s), loss is 2.75470, batch_train accuracy is 0.3281\n",
      "INFO: After 1092 training iteration(s), loss is 2.74088, batch_train accuracy is 0.3457\n",
      "INFO: After 1093 training iteration(s), loss is 2.74745, batch_train accuracy is 0.3398\n",
      "INFO: After 1094 training iteration(s), loss is 2.74832, batch_train accuracy is 0.3262\n",
      "INFO: After 1095 training iteration(s), loss is 2.75083, batch_train accuracy is 0.3203\n",
      "INFO: After 1096 training iteration(s), loss is 2.74164, batch_train accuracy is 0.3340\n",
      "INFO: After 1097 training iteration(s), loss is 2.74824, batch_train accuracy is 0.3145\n",
      "INFO: After 1098 training iteration(s), loss is 2.75209, batch_train accuracy is 0.3145\n",
      "INFO: After 1099 training iteration(s), loss is 2.74235, batch_train accuracy is 0.3359\n",
      "INFO: After 1100 training iteration(s), loss is 2.74603, batch_train accuracy is 0.3281\n",
      "Lenet-5_model-1100.ckpt saved!\n",
      "INFO: After 1101 training iteration(s), loss is 2.73134, batch_train accuracy is 0.3125\n",
      "INFO: After 1102 training iteration(s), loss is 2.75985, batch_train accuracy is 0.3203\n",
      "INFO: After 1103 training iteration(s), loss is 2.72777, batch_train accuracy is 0.3672\n",
      "INFO: After 1104 training iteration(s), loss is 2.74862, batch_train accuracy is 0.2930\n",
      "INFO: After 1105 training iteration(s), loss is 2.76861, batch_train accuracy is 0.3164\n",
      "INFO: After 1106 training iteration(s), loss is 2.77297, batch_train accuracy is 0.2949\n",
      "INFO: After 1107 training iteration(s), loss is 2.76456, batch_train accuracy is 0.2910\n",
      "INFO: After 1108 training iteration(s), loss is 2.74788, batch_train accuracy is 0.3066\n",
      "INFO: After 1109 training iteration(s), loss is 2.73156, batch_train accuracy is 0.3535\n",
      "INFO: After 1110 training iteration(s), loss is 2.75317, batch_train accuracy is 0.2988\n",
      "INFO: After 1111 training iteration(s), loss is 2.71056, batch_train accuracy is 0.3613\n",
      "INFO: After 1112 training iteration(s), loss is 2.72508, batch_train accuracy is 0.3633\n",
      "INFO: After 1113 training iteration(s), loss is 2.73782, batch_train accuracy is 0.3301\n",
      "INFO: After 1114 training iteration(s), loss is 2.73544, batch_train accuracy is 0.3027\n",
      "INFO: After 1115 training iteration(s), loss is 2.72151, batch_train accuracy is 0.3301\n",
      "INFO: After 1116 training iteration(s), loss is 2.70275, batch_train accuracy is 0.3555\n",
      "INFO: After 1117 training iteration(s), loss is 2.75194, batch_train accuracy is 0.3203\n",
      "INFO: After 1118 training iteration(s), loss is 2.72037, batch_train accuracy is 0.3438\n",
      "INFO: After 1119 training iteration(s), loss is 2.72756, batch_train accuracy is 0.3379\n",
      "INFO: After 1120 training iteration(s), loss is 2.71503, batch_train accuracy is 0.3516\n",
      "INFO: After 1121 training iteration(s), loss is 2.74233, batch_train accuracy is 0.3125\n",
      "INFO: After 1122 training iteration(s), loss is 2.74181, batch_train accuracy is 0.3047\n",
      "INFO: After 1123 training iteration(s), loss is 2.70670, batch_train accuracy is 0.3555\n",
      "INFO: After 1124 training iteration(s), loss is 2.74144, batch_train accuracy is 0.3457\n",
      "INFO: After 1125 training iteration(s), loss is 2.71510, batch_train accuracy is 0.3301\n",
      "INFO: After 1126 training iteration(s), loss is 2.72574, batch_train accuracy is 0.3320\n",
      "INFO: After 1127 training iteration(s), loss is 2.70946, batch_train accuracy is 0.3672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: After 1128 training iteration(s), loss is 2.71908, batch_train accuracy is 0.3730\n",
      "INFO: After 1129 training iteration(s), loss is 2.72862, batch_train accuracy is 0.3691\n",
      "INFO: After 1130 training iteration(s), loss is 2.72329, batch_train accuracy is 0.3145\n",
      "INFO: After 1131 training iteration(s), loss is 2.71571, batch_train accuracy is 0.3594\n",
      "INFO: After 1132 training iteration(s), loss is 2.70998, batch_train accuracy is 0.3594\n",
      "INFO: After 1133 training iteration(s), loss is 2.73026, batch_train accuracy is 0.3203\n",
      "INFO: After 1134 training iteration(s), loss is 2.75638, batch_train accuracy is 0.2910\n",
      "INFO: After 1135 training iteration(s), loss is 2.70758, batch_train accuracy is 0.3262\n",
      "INFO: After 1136 training iteration(s), loss is 2.73539, batch_train accuracy is 0.3164\n",
      "After 8 training epoch(s)(X117), loss is 2.75698, train accuracy is 0.3179\n",
      "Lenet-5_model-8x117 saved!\n",
      "INFO: After 1137 training iteration(s), loss is 2.70834, batch_train accuracy is 0.3477\n",
      "INFO: After 1138 training iteration(s), loss is 2.72740, batch_train accuracy is 0.3262\n",
      "INFO: After 1139 training iteration(s), loss is 2.69396, batch_train accuracy is 0.3789\n",
      "INFO: After 1140 training iteration(s), loss is 2.74500, batch_train accuracy is 0.3379\n",
      "INFO: After 1141 training iteration(s), loss is 2.71364, batch_train accuracy is 0.3457\n",
      "INFO: After 1142 training iteration(s), loss is 2.71464, batch_train accuracy is 0.3594\n",
      "INFO: After 1143 training iteration(s), loss is 2.69266, batch_train accuracy is 0.3711\n",
      "INFO: After 1144 training iteration(s), loss is 2.70278, batch_train accuracy is 0.3574\n",
      "INFO: After 1145 training iteration(s), loss is 2.71829, batch_train accuracy is 0.3281\n",
      "INFO: After 1146 training iteration(s), loss is 2.73365, batch_train accuracy is 0.3340\n",
      "INFO: After 1147 training iteration(s), loss is 2.69218, batch_train accuracy is 0.3574\n",
      "INFO: After 1148 training iteration(s), loss is 2.70244, batch_train accuracy is 0.3594\n",
      "INFO: After 1149 training iteration(s), loss is 2.71744, batch_train accuracy is 0.3477\n",
      "INFO: After 1150 training iteration(s), loss is 2.69587, batch_train accuracy is 0.3770\n",
      "INFO: After 1151 training iteration(s), loss is 2.70926, batch_train accuracy is 0.3477\n",
      "INFO: After 1152 training iteration(s), loss is 2.71252, batch_train accuracy is 0.3320\n",
      "INFO: After 1153 training iteration(s), loss is 2.70889, batch_train accuracy is 0.3359\n",
      "INFO: After 1154 training iteration(s), loss is 2.71806, batch_train accuracy is 0.3477\n",
      "INFO: After 1155 training iteration(s), loss is 2.70437, batch_train accuracy is 0.3379\n",
      "INFO: After 1156 training iteration(s), loss is 2.69507, batch_train accuracy is 0.3418\n",
      "INFO: After 1157 training iteration(s), loss is 2.72110, batch_train accuracy is 0.3828\n",
      "INFO: After 1158 training iteration(s), loss is 2.72196, batch_train accuracy is 0.3301\n",
      "INFO: After 1159 training iteration(s), loss is 2.69030, batch_train accuracy is 0.3926\n",
      "INFO: After 1160 training iteration(s), loss is 2.72986, batch_train accuracy is 0.3027\n",
      "INFO: After 1161 training iteration(s), loss is 2.71070, batch_train accuracy is 0.3340\n",
      "INFO: After 1162 training iteration(s), loss is 2.70096, batch_train accuracy is 0.3672\n",
      "INFO: After 1163 training iteration(s), loss is 2.68417, batch_train accuracy is 0.3730\n",
      "INFO: After 1164 training iteration(s), loss is 2.66119, batch_train accuracy is 0.4102\n",
      "INFO: After 1165 training iteration(s), loss is 2.70330, batch_train accuracy is 0.3340\n",
      "INFO: After 1166 training iteration(s), loss is 2.75130, batch_train accuracy is 0.2949\n",
      "INFO: After 1167 training iteration(s), loss is 2.68562, batch_train accuracy is 0.3750\n",
      "INFO: After 1168 training iteration(s), loss is 2.68224, batch_train accuracy is 0.3438\n",
      "INFO: After 1169 training iteration(s), loss is 2.72404, batch_train accuracy is 0.3184\n",
      "INFO: After 1170 training iteration(s), loss is 2.67163, batch_train accuracy is 0.3828\n",
      "INFO: After 1171 training iteration(s), loss is 2.71644, batch_train accuracy is 0.3164\n",
      "INFO: After 1172 training iteration(s), loss is 2.70004, batch_train accuracy is 0.3594\n",
      "INFO: After 1173 training iteration(s), loss is 2.66715, batch_train accuracy is 0.3555\n",
      "INFO: After 1174 training iteration(s), loss is 2.69486, batch_train accuracy is 0.3633\n",
      "INFO: After 1175 training iteration(s), loss is 2.69622, batch_train accuracy is 0.3340\n",
      "INFO: After 1176 training iteration(s), loss is 2.68064, batch_train accuracy is 0.3887\n",
      "INFO: After 1177 training iteration(s), loss is 2.72633, batch_train accuracy is 0.3242\n",
      "INFO: After 1178 training iteration(s), loss is 2.68010, batch_train accuracy is 0.3730\n",
      "INFO: After 1179 training iteration(s), loss is 2.68637, batch_train accuracy is 0.3398\n",
      "INFO: After 1180 training iteration(s), loss is 2.68419, batch_train accuracy is 0.3867\n",
      "INFO: After 1181 training iteration(s), loss is 2.68144, batch_train accuracy is 0.3730\n",
      "INFO: After 1182 training iteration(s), loss is 2.68101, batch_train accuracy is 0.3516\n",
      "INFO: After 1183 training iteration(s), loss is 2.70544, batch_train accuracy is 0.3711\n",
      "INFO: After 1184 training iteration(s), loss is 2.67293, batch_train accuracy is 0.3750\n",
      "INFO: After 1185 training iteration(s), loss is 2.68124, batch_train accuracy is 0.3672\n",
      "INFO: After 1186 training iteration(s), loss is 2.68999, batch_train accuracy is 0.3418\n",
      "INFO: After 1187 training iteration(s), loss is 2.70612, batch_train accuracy is 0.3359\n",
      "INFO: After 1188 training iteration(s), loss is 2.68589, batch_train accuracy is 0.3633\n",
      "INFO: After 1189 training iteration(s), loss is 2.72587, batch_train accuracy is 0.3262\n",
      "INFO: After 1190 training iteration(s), loss is 2.66807, batch_train accuracy is 0.3711\n",
      "INFO: After 1191 training iteration(s), loss is 2.67622, batch_train accuracy is 0.3672\n",
      "INFO: After 1192 training iteration(s), loss is 2.67300, batch_train accuracy is 0.3770\n",
      "INFO: After 1193 training iteration(s), loss is 2.72400, batch_train accuracy is 0.3340\n",
      "INFO: After 1194 training iteration(s), loss is 2.67504, batch_train accuracy is 0.3828\n",
      "INFO: After 1195 training iteration(s), loss is 2.69383, batch_train accuracy is 0.3281\n",
      "INFO: After 1196 training iteration(s), loss is 2.66451, batch_train accuracy is 0.3672\n",
      "INFO: After 1197 training iteration(s), loss is 2.65997, batch_train accuracy is 0.3730\n",
      "INFO: After 1198 training iteration(s), loss is 2.68611, batch_train accuracy is 0.3711\n",
      "INFO: After 1199 training iteration(s), loss is 2.67981, batch_train accuracy is 0.3809\n",
      "INFO: After 1200 training iteration(s), loss is 2.66561, batch_train accuracy is 0.3711\n",
      "Lenet-5_model-1200.ckpt saved!\n",
      "INFO: After 1201 training iteration(s), loss is 2.64471, batch_train accuracy is 0.3828\n",
      "INFO: After 1202 training iteration(s), loss is 2.68040, batch_train accuracy is 0.3340\n",
      "INFO: After 1203 training iteration(s), loss is 2.62297, batch_train accuracy is 0.3730\n",
      "INFO: After 1204 training iteration(s), loss is 2.63201, batch_train accuracy is 0.3809\n",
      "INFO: After 1205 training iteration(s), loss is 2.68303, batch_train accuracy is 0.3535\n",
      "INFO: After 1206 training iteration(s), loss is 2.67333, batch_train accuracy is 0.3613\n",
      "INFO: After 1207 training iteration(s), loss is 2.64356, batch_train accuracy is 0.3809\n",
      "INFO: After 1208 training iteration(s), loss is 2.66675, batch_train accuracy is 0.3789\n",
      "INFO: After 1209 training iteration(s), loss is 2.65817, batch_train accuracy is 0.3477\n",
      "INFO: After 1210 training iteration(s), loss is 2.68969, batch_train accuracy is 0.3574\n",
      "INFO: After 1211 training iteration(s), loss is 2.65604, batch_train accuracy is 0.3652\n",
      "INFO: After 1212 training iteration(s), loss is 2.63878, batch_train accuracy is 0.3867\n",
      "INFO: After 1213 training iteration(s), loss is 2.65538, batch_train accuracy is 0.3906\n",
      "INFO: After 1214 training iteration(s), loss is 2.68271, batch_train accuracy is 0.3652\n",
      "INFO: After 1215 training iteration(s), loss is 2.66048, batch_train accuracy is 0.3887\n",
      "INFO: After 1216 training iteration(s), loss is 2.65639, batch_train accuracy is 0.3672\n",
      "INFO: After 1217 training iteration(s), loss is 2.69702, batch_train accuracy is 0.3301\n",
      "INFO: After 1218 training iteration(s), loss is 2.64921, batch_train accuracy is 0.3672\n",
      "INFO: After 1219 training iteration(s), loss is 2.64985, batch_train accuracy is 0.3984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: After 1220 training iteration(s), loss is 2.63749, batch_train accuracy is 0.3945\n",
      "INFO: After 1221 training iteration(s), loss is 2.65839, batch_train accuracy is 0.3633\n",
      "INFO: After 1222 training iteration(s), loss is 2.66284, batch_train accuracy is 0.3555\n",
      "INFO: After 1223 training iteration(s), loss is 2.66158, batch_train accuracy is 0.3887\n",
      "INFO: After 1224 training iteration(s), loss is 2.67491, batch_train accuracy is 0.3438\n",
      "INFO: After 1225 training iteration(s), loss is 2.66929, batch_train accuracy is 0.3730\n",
      "INFO: After 1226 training iteration(s), loss is 2.68587, batch_train accuracy is 0.3633\n",
      "INFO: After 1227 training iteration(s), loss is 2.68183, batch_train accuracy is 0.3574\n",
      "INFO: After 1228 training iteration(s), loss is 2.64817, batch_train accuracy is 0.4043\n",
      "INFO: After 1229 training iteration(s), loss is 2.65538, batch_train accuracy is 0.3574\n",
      "INFO: After 1230 training iteration(s), loss is 2.61754, batch_train accuracy is 0.3945\n",
      "INFO: After 1231 training iteration(s), loss is 2.63473, batch_train accuracy is 0.4004\n",
      "INFO: After 1232 training iteration(s), loss is 2.63941, batch_train accuracy is 0.3672\n",
      "INFO: After 1233 training iteration(s), loss is 2.64782, batch_train accuracy is 0.3730\n",
      "INFO: After 1234 training iteration(s), loss is 2.63087, batch_train accuracy is 0.3926\n",
      "INFO: After 1235 training iteration(s), loss is 2.63824, batch_train accuracy is 0.3691\n",
      "INFO: After 1236 training iteration(s), loss is 2.67952, batch_train accuracy is 0.3477\n",
      "INFO: After 1237 training iteration(s), loss is 2.63431, batch_train accuracy is 0.3711\n",
      "INFO: After 1238 training iteration(s), loss is 2.64547, batch_train accuracy is 0.3945\n",
      "INFO: After 1239 training iteration(s), loss is 2.63806, batch_train accuracy is 0.3594\n",
      "INFO: After 1240 training iteration(s), loss is 2.62903, batch_train accuracy is 0.3906\n",
      "INFO: After 1241 training iteration(s), loss is 2.62476, batch_train accuracy is 0.3594\n",
      "INFO: After 1242 training iteration(s), loss is 2.62492, batch_train accuracy is 0.3867\n",
      "INFO: After 1243 training iteration(s), loss is 2.67362, batch_train accuracy is 0.3574\n",
      "INFO: After 1244 training iteration(s), loss is 2.63358, batch_train accuracy is 0.3457\n",
      "INFO: After 1245 training iteration(s), loss is 2.62414, batch_train accuracy is 0.4004\n",
      "INFO: After 1246 training iteration(s), loss is 2.61051, batch_train accuracy is 0.4121\n",
      "INFO: After 1247 training iteration(s), loss is 2.62067, batch_train accuracy is 0.4004\n",
      "INFO: After 1248 training iteration(s), loss is 2.61359, batch_train accuracy is 0.3848\n",
      "INFO: After 1249 training iteration(s), loss is 2.63683, batch_train accuracy is 0.3730\n",
      "INFO: After 1250 training iteration(s), loss is 2.60776, batch_train accuracy is 0.3945\n",
      "INFO: After 1251 training iteration(s), loss is 2.62750, batch_train accuracy is 0.3750\n",
      "INFO: After 1252 training iteration(s), loss is 2.65001, batch_train accuracy is 0.3965\n",
      "INFO: After 1253 training iteration(s), loss is 2.63899, batch_train accuracy is 0.3633\n",
      "After 9 training epoch(s)(X117), loss is 2.67582, train accuracy is 0.3633\n",
      "Lenet-5_model-9x117 saved!\n",
      "INFO: After 1254 training iteration(s), loss is 2.62170, batch_train accuracy is 0.3906\n",
      "INFO: After 1255 training iteration(s), loss is 2.64181, batch_train accuracy is 0.3594\n",
      "INFO: After 1256 training iteration(s), loss is 2.62213, batch_train accuracy is 0.4043\n",
      "INFO: After 1257 training iteration(s), loss is 2.62309, batch_train accuracy is 0.3906\n",
      "INFO: After 1258 training iteration(s), loss is 2.59745, batch_train accuracy is 0.4102\n",
      "INFO: After 1259 training iteration(s), loss is 2.62498, batch_train accuracy is 0.3789\n",
      "INFO: After 1260 training iteration(s), loss is 2.61528, batch_train accuracy is 0.4141\n",
      "INFO: After 1261 training iteration(s), loss is 2.61165, batch_train accuracy is 0.4004\n",
      "INFO: After 1262 training iteration(s), loss is 2.66625, batch_train accuracy is 0.3438\n",
      "INFO: After 1263 training iteration(s), loss is 2.62673, batch_train accuracy is 0.3809\n",
      "INFO: After 1264 training iteration(s), loss is 2.59371, batch_train accuracy is 0.4316\n",
      "INFO: After 1265 training iteration(s), loss is 2.60669, batch_train accuracy is 0.4062\n",
      "INFO: After 1266 training iteration(s), loss is 2.58917, batch_train accuracy is 0.4258\n",
      "INFO: After 1267 training iteration(s), loss is 2.60553, batch_train accuracy is 0.4023\n",
      "INFO: After 1268 training iteration(s), loss is 2.61744, batch_train accuracy is 0.3613\n",
      "INFO: After 1269 training iteration(s), loss is 2.58875, batch_train accuracy is 0.4062\n",
      "INFO: After 1270 training iteration(s), loss is 2.62199, batch_train accuracy is 0.3789\n",
      "INFO: After 1271 training iteration(s), loss is 2.61204, batch_train accuracy is 0.3789\n",
      "INFO: After 1272 training iteration(s), loss is 2.57729, batch_train accuracy is 0.4316\n",
      "INFO: After 1273 training iteration(s), loss is 2.59868, batch_train accuracy is 0.3809\n",
      "INFO: After 1274 training iteration(s), loss is 2.65066, batch_train accuracy is 0.3867\n",
      "INFO: After 1275 training iteration(s), loss is 2.56817, batch_train accuracy is 0.4160\n",
      "INFO: After 1276 training iteration(s), loss is 2.61022, batch_train accuracy is 0.3828\n",
      "INFO: After 1277 training iteration(s), loss is 2.63407, batch_train accuracy is 0.3730\n",
      "INFO: After 1278 training iteration(s), loss is 2.61373, batch_train accuracy is 0.3887\n",
      "INFO: After 1279 training iteration(s), loss is 2.63650, batch_train accuracy is 0.3594\n",
      "INFO: After 1280 training iteration(s), loss is 2.58834, batch_train accuracy is 0.4160\n",
      "INFO: After 1281 training iteration(s), loss is 2.56964, batch_train accuracy is 0.4121\n",
      "INFO: After 1282 training iteration(s), loss is 2.59194, batch_train accuracy is 0.3945\n",
      "INFO: After 1283 training iteration(s), loss is 2.61182, batch_train accuracy is 0.3770\n",
      "INFO: After 1284 training iteration(s), loss is 2.60215, batch_train accuracy is 0.3848\n",
      "INFO: After 1285 training iteration(s), loss is 2.60941, batch_train accuracy is 0.3750\n",
      "INFO: After 1286 training iteration(s), loss is 2.55668, batch_train accuracy is 0.4453\n",
      "INFO: After 1287 training iteration(s), loss is 2.60166, batch_train accuracy is 0.3750\n",
      "INFO: After 1288 training iteration(s), loss is 2.58374, batch_train accuracy is 0.4043\n",
      "INFO: After 1289 training iteration(s), loss is 2.63642, batch_train accuracy is 0.3672\n",
      "INFO: After 1290 training iteration(s), loss is 2.55982, batch_train accuracy is 0.4160\n",
      "INFO: After 1291 training iteration(s), loss is 2.59895, batch_train accuracy is 0.3848\n",
      "INFO: After 1292 training iteration(s), loss is 2.61216, batch_train accuracy is 0.3750\n",
      "INFO: After 1293 training iteration(s), loss is 2.58301, batch_train accuracy is 0.4023\n",
      "INFO: After 1294 training iteration(s), loss is 2.59967, batch_train accuracy is 0.3867\n",
      "INFO: After 1295 training iteration(s), loss is 2.63604, batch_train accuracy is 0.3711\n",
      "INFO: After 1296 training iteration(s), loss is 2.59697, batch_train accuracy is 0.3926\n",
      "INFO: After 1297 training iteration(s), loss is 2.59041, batch_train accuracy is 0.3906\n",
      "INFO: After 1298 training iteration(s), loss is 2.59793, batch_train accuracy is 0.3789\n",
      "INFO: After 1299 training iteration(s), loss is 2.59462, batch_train accuracy is 0.3906\n",
      "INFO: After 1300 training iteration(s), loss is 2.58599, batch_train accuracy is 0.3984\n",
      "Lenet-5_model-1300.ckpt saved!\n",
      "INFO: After 1301 training iteration(s), loss is 2.58101, batch_train accuracy is 0.4062\n",
      "INFO: After 1302 training iteration(s), loss is 2.57098, batch_train accuracy is 0.4121\n",
      "INFO: After 1303 training iteration(s), loss is 2.62451, batch_train accuracy is 0.3867\n",
      "INFO: After 1304 training iteration(s), loss is 2.57250, batch_train accuracy is 0.3984\n",
      "INFO: After 1305 training iteration(s), loss is 2.58348, batch_train accuracy is 0.4336\n",
      "INFO: After 1306 training iteration(s), loss is 2.60337, batch_train accuracy is 0.3770\n",
      "INFO: After 1307 training iteration(s), loss is 2.65565, batch_train accuracy is 0.3652\n",
      "INFO: After 1308 training iteration(s), loss is 2.56222, batch_train accuracy is 0.4023\n",
      "INFO: After 1309 training iteration(s), loss is 2.55841, batch_train accuracy is 0.4258\n",
      "INFO: After 1310 training iteration(s), loss is 2.58220, batch_train accuracy is 0.3750\n",
      "INFO: After 1311 training iteration(s), loss is 2.59017, batch_train accuracy is 0.3926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: After 1312 training iteration(s), loss is 2.56118, batch_train accuracy is 0.4062\n",
      "INFO: After 1313 training iteration(s), loss is 2.58068, batch_train accuracy is 0.3887\n",
      "INFO: After 1314 training iteration(s), loss is 2.56698, batch_train accuracy is 0.4082\n",
      "INFO: After 1315 training iteration(s), loss is 2.56129, batch_train accuracy is 0.4141\n",
      "INFO: After 1316 training iteration(s), loss is 2.57878, batch_train accuracy is 0.3984\n",
      "INFO: After 1317 training iteration(s), loss is 2.54811, batch_train accuracy is 0.4297\n",
      "INFO: After 1318 training iteration(s), loss is 2.56681, batch_train accuracy is 0.4316\n",
      "INFO: After 1319 training iteration(s), loss is 2.53733, batch_train accuracy is 0.4219\n",
      "INFO: After 1320 training iteration(s), loss is 2.55494, batch_train accuracy is 0.4180\n",
      "INFO: After 1321 training iteration(s), loss is 2.53272, batch_train accuracy is 0.4395\n",
      "INFO: After 1322 training iteration(s), loss is 2.52911, batch_train accuracy is 0.4141\n",
      "INFO: After 1323 training iteration(s), loss is 2.56782, batch_train accuracy is 0.3828\n",
      "INFO: After 1324 training iteration(s), loss is 2.53681, batch_train accuracy is 0.4199\n",
      "INFO: After 1325 training iteration(s), loss is 2.57585, batch_train accuracy is 0.3828\n",
      "INFO: After 1326 training iteration(s), loss is 2.56399, batch_train accuracy is 0.3730\n",
      "INFO: After 1327 training iteration(s), loss is 2.57907, batch_train accuracy is 0.3906\n",
      "INFO: After 1328 training iteration(s), loss is 2.51588, batch_train accuracy is 0.4199\n",
      "INFO: After 1329 training iteration(s), loss is 2.53417, batch_train accuracy is 0.4199\n",
      "INFO: After 1330 training iteration(s), loss is 2.53425, batch_train accuracy is 0.4316\n",
      "INFO: After 1331 training iteration(s), loss is 2.56814, batch_train accuracy is 0.4336\n",
      "INFO: After 1332 training iteration(s), loss is 2.57096, batch_train accuracy is 0.3965\n",
      "INFO: After 1333 training iteration(s), loss is 2.54853, batch_train accuracy is 0.4180\n",
      "INFO: After 1334 training iteration(s), loss is 2.52351, batch_train accuracy is 0.4355\n",
      "INFO: After 1335 training iteration(s), loss is 2.56519, batch_train accuracy is 0.3984\n",
      "INFO: After 1336 training iteration(s), loss is 2.53546, batch_train accuracy is 0.4395\n",
      "INFO: After 1337 training iteration(s), loss is 2.56884, batch_train accuracy is 0.4043\n",
      "INFO: After 1338 training iteration(s), loss is 2.56477, batch_train accuracy is 0.3672\n",
      "INFO: After 1339 training iteration(s), loss is 2.54692, batch_train accuracy is 0.4043\n",
      "INFO: After 1340 training iteration(s), loss is 2.53743, batch_train accuracy is 0.4277\n",
      "INFO: After 1341 training iteration(s), loss is 2.55294, batch_train accuracy is 0.4121\n",
      "INFO: After 1342 training iteration(s), loss is 2.59943, batch_train accuracy is 0.3691\n",
      "INFO: After 1343 training iteration(s), loss is 2.52186, batch_train accuracy is 0.4395\n",
      "INFO: After 1344 training iteration(s), loss is 2.54251, batch_train accuracy is 0.4004\n",
      "INFO: After 1345 training iteration(s), loss is 2.50593, batch_train accuracy is 0.4355\n",
      "INFO: After 1346 training iteration(s), loss is 2.51917, batch_train accuracy is 0.4160\n",
      "INFO: After 1347 training iteration(s), loss is 2.51025, batch_train accuracy is 0.4453\n",
      "INFO: After 1348 training iteration(s), loss is 2.54865, batch_train accuracy is 0.3945\n",
      "INFO: After 1349 training iteration(s), loss is 2.49937, batch_train accuracy is 0.4727\n",
      "INFO: After 1350 training iteration(s), loss is 2.50285, batch_train accuracy is 0.4180\n",
      "INFO: After 1351 training iteration(s), loss is 2.50519, batch_train accuracy is 0.4395\n",
      "INFO: After 1352 training iteration(s), loss is 2.54081, batch_train accuracy is 0.3906\n",
      "INFO: After 1353 training iteration(s), loss is 2.52801, batch_train accuracy is 0.4160\n",
      "INFO: After 1354 training iteration(s), loss is 2.54666, batch_train accuracy is 0.3770\n",
      "INFO: After 1355 training iteration(s), loss is 2.52051, batch_train accuracy is 0.4043\n",
      "INFO: After 1356 training iteration(s), loss is 2.51630, batch_train accuracy is 0.4336\n",
      "INFO: After 1357 training iteration(s), loss is 2.52543, batch_train accuracy is 0.3984\n",
      "INFO: After 1358 training iteration(s), loss is 2.52920, batch_train accuracy is 0.4121\n",
      "INFO: After 1359 training iteration(s), loss is 2.51345, batch_train accuracy is 0.4375\n",
      "INFO: After 1360 training iteration(s), loss is 2.52589, batch_train accuracy is 0.3828\n",
      "INFO: After 1361 training iteration(s), loss is 2.56840, batch_train accuracy is 0.3750\n",
      "INFO: After 1362 training iteration(s), loss is 2.45518, batch_train accuracy is 0.4824\n",
      "INFO: After 1363 training iteration(s), loss is 2.47241, batch_train accuracy is 0.4629\n",
      "INFO: After 1364 training iteration(s), loss is 2.51477, batch_train accuracy is 0.4102\n",
      "INFO: After 1365 training iteration(s), loss is 2.50933, batch_train accuracy is 0.4180\n",
      "INFO: After 1366 training iteration(s), loss is 2.49421, batch_train accuracy is 0.4590\n",
      "INFO: After 1367 training iteration(s), loss is 2.48758, batch_train accuracy is 0.4453\n",
      "INFO: After 1368 training iteration(s), loss is 2.55974, batch_train accuracy is 0.4121\n",
      "INFO: After 1369 training iteration(s), loss is 2.49453, batch_train accuracy is 0.4316\n",
      "INFO: After 1370 training iteration(s), loss is 2.52982, batch_train accuracy is 0.4004\n",
      "After 10 training epoch(s)(X117), loss is 2.56977, train accuracy is 0.4043\n",
      "Lenet-5_model-10x117 saved!\n",
      "INFO: After 1371 training iteration(s), loss is 2.52372, batch_train accuracy is 0.4043\n",
      "INFO: After 1372 training iteration(s), loss is 2.53388, batch_train accuracy is 0.3535\n",
      "INFO: After 1373 training iteration(s), loss is 2.45950, batch_train accuracy is 0.4785\n",
      "INFO: After 1374 training iteration(s), loss is 2.51072, batch_train accuracy is 0.4043\n",
      "INFO: After 1375 training iteration(s), loss is 2.47695, batch_train accuracy is 0.4121\n",
      "INFO: After 1376 training iteration(s), loss is 2.52316, batch_train accuracy is 0.4023\n",
      "INFO: After 1377 training iteration(s), loss is 2.49492, batch_train accuracy is 0.4590\n",
      "INFO: After 1378 training iteration(s), loss is 2.49722, batch_train accuracy is 0.4336\n",
      "INFO: After 1379 training iteration(s), loss is 2.50079, batch_train accuracy is 0.4180\n",
      "INFO: After 1380 training iteration(s), loss is 2.45963, batch_train accuracy is 0.4648\n",
      "INFO: After 1381 training iteration(s), loss is 2.49939, batch_train accuracy is 0.4297\n",
      "INFO: After 1382 training iteration(s), loss is 2.54406, batch_train accuracy is 0.3711\n",
      "INFO: After 1383 training iteration(s), loss is 2.46278, batch_train accuracy is 0.4590\n",
      "INFO: After 1384 training iteration(s), loss is 2.50582, batch_train accuracy is 0.4375\n",
      "INFO: After 1385 training iteration(s), loss is 2.52049, batch_train accuracy is 0.3867\n",
      "INFO: After 1386 training iteration(s), loss is 2.49229, batch_train accuracy is 0.4297\n",
      "INFO: After 1387 training iteration(s), loss is 2.47327, batch_train accuracy is 0.4023\n",
      "INFO: After 1388 training iteration(s), loss is 2.47943, batch_train accuracy is 0.4219\n",
      "INFO: After 1389 training iteration(s), loss is 2.48204, batch_train accuracy is 0.4531\n",
      "INFO: After 1390 training iteration(s), loss is 2.47940, batch_train accuracy is 0.4453\n",
      "INFO: After 1391 training iteration(s), loss is 2.45870, batch_train accuracy is 0.4512\n",
      "INFO: After 1392 training iteration(s), loss is 2.47895, batch_train accuracy is 0.4160\n",
      "INFO: After 1393 training iteration(s), loss is 2.49609, batch_train accuracy is 0.4102\n",
      "INFO: After 1394 training iteration(s), loss is 2.53166, batch_train accuracy is 0.4004\n",
      "INFO: After 1395 training iteration(s), loss is 2.50910, batch_train accuracy is 0.4219\n",
      "INFO: After 1396 training iteration(s), loss is 2.45440, batch_train accuracy is 0.4414\n",
      "INFO: After 1397 training iteration(s), loss is 2.49062, batch_train accuracy is 0.4219\n",
      "INFO: After 1398 training iteration(s), loss is 2.42440, batch_train accuracy is 0.4824\n",
      "INFO: After 1399 training iteration(s), loss is 2.47141, batch_train accuracy is 0.4336\n",
      "INFO: After 1400 training iteration(s), loss is 2.48524, batch_train accuracy is 0.4121\n",
      "Lenet-5_model-1400.ckpt saved!\n",
      "INFO: After 1401 training iteration(s), loss is 2.47753, batch_train accuracy is 0.4082\n",
      "INFO: After 1402 training iteration(s), loss is 2.49417, batch_train accuracy is 0.4160\n",
      "INFO: After 1403 training iteration(s), loss is 2.47649, batch_train accuracy is 0.4238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: After 1404 training iteration(s), loss is 2.46535, batch_train accuracy is 0.4277\n",
      "INFO: After 1405 training iteration(s), loss is 2.48018, batch_train accuracy is 0.4258\n",
      "INFO: After 1406 training iteration(s), loss is 2.47132, batch_train accuracy is 0.4297\n",
      "INFO: After 1407 training iteration(s), loss is 2.44225, batch_train accuracy is 0.4551\n",
      "INFO: After 1408 training iteration(s), loss is 2.43179, batch_train accuracy is 0.4941\n",
      "INFO: After 1409 training iteration(s), loss is 2.44167, batch_train accuracy is 0.4688\n",
      "INFO: After 1410 training iteration(s), loss is 2.47478, batch_train accuracy is 0.4316\n",
      "INFO: After 1411 training iteration(s), loss is 2.47853, batch_train accuracy is 0.4121\n",
      "INFO: After 1412 training iteration(s), loss is 2.49591, batch_train accuracy is 0.4473\n",
      "INFO: After 1413 training iteration(s), loss is 2.45505, batch_train accuracy is 0.4473\n",
      "INFO: After 1414 training iteration(s), loss is 2.42290, batch_train accuracy is 0.4492\n",
      "INFO: After 1415 training iteration(s), loss is 2.44126, batch_train accuracy is 0.4590\n",
      "INFO: After 1416 training iteration(s), loss is 2.49320, batch_train accuracy is 0.4023\n",
      "INFO: After 1417 training iteration(s), loss is 2.48428, batch_train accuracy is 0.4160\n",
      "INFO: After 1418 training iteration(s), loss is 2.49040, batch_train accuracy is 0.4082\n",
      "INFO: After 1419 training iteration(s), loss is 2.51463, batch_train accuracy is 0.4180\n",
      "INFO: After 1420 training iteration(s), loss is 2.48061, batch_train accuracy is 0.4141\n",
      "INFO: After 1421 training iteration(s), loss is 2.46567, batch_train accuracy is 0.4160\n",
      "INFO: After 1422 training iteration(s), loss is 2.45590, batch_train accuracy is 0.4414\n",
      "INFO: After 1423 training iteration(s), loss is 2.51859, batch_train accuracy is 0.4180\n",
      "INFO: After 1424 training iteration(s), loss is 2.47526, batch_train accuracy is 0.4277\n",
      "INFO: After 1425 training iteration(s), loss is 2.46583, batch_train accuracy is 0.4336\n",
      "INFO: After 1426 training iteration(s), loss is 2.47815, batch_train accuracy is 0.4336\n",
      "INFO: After 1427 training iteration(s), loss is 2.41868, batch_train accuracy is 0.4570\n",
      "INFO: After 1428 training iteration(s), loss is 2.44934, batch_train accuracy is 0.4336\n",
      "INFO: After 1429 training iteration(s), loss is 2.44153, batch_train accuracy is 0.4336\n",
      "INFO: After 1430 training iteration(s), loss is 2.44428, batch_train accuracy is 0.4434\n",
      "INFO: After 1431 training iteration(s), loss is 2.42621, batch_train accuracy is 0.4375\n",
      "INFO: After 1432 training iteration(s), loss is 2.41005, batch_train accuracy is 0.4453\n",
      "INFO: After 1433 training iteration(s), loss is 2.50830, batch_train accuracy is 0.4082\n",
      "INFO: After 1434 training iteration(s), loss is 2.43270, batch_train accuracy is 0.4668\n",
      "INFO: After 1435 training iteration(s), loss is 2.43740, batch_train accuracy is 0.4023\n",
      "INFO: After 1436 training iteration(s), loss is 2.44509, batch_train accuracy is 0.4395\n",
      "INFO: After 1437 training iteration(s), loss is 2.37442, batch_train accuracy is 0.4688\n",
      "INFO: After 1438 training iteration(s), loss is 2.40723, batch_train accuracy is 0.4668\n",
      "INFO: After 1439 training iteration(s), loss is 2.37276, batch_train accuracy is 0.5000\n",
      "INFO: After 1440 training iteration(s), loss is 2.41263, batch_train accuracy is 0.4609\n",
      "INFO: After 1441 training iteration(s), loss is 2.42546, batch_train accuracy is 0.4395\n",
      "INFO: After 1442 training iteration(s), loss is 2.44487, batch_train accuracy is 0.4219\n",
      "INFO: After 1443 training iteration(s), loss is 2.43505, batch_train accuracy is 0.4531\n",
      "INFO: After 1444 training iteration(s), loss is 2.38851, batch_train accuracy is 0.4707\n",
      "INFO: After 1445 training iteration(s), loss is 2.44180, batch_train accuracy is 0.4395\n",
      "INFO: After 1446 training iteration(s), loss is 2.43834, batch_train accuracy is 0.4668\n",
      "INFO: After 1447 training iteration(s), loss is 2.40129, batch_train accuracy is 0.4434\n",
      "INFO: After 1448 training iteration(s), loss is 2.41071, batch_train accuracy is 0.4551\n",
      "INFO: After 1449 training iteration(s), loss is 2.41530, batch_train accuracy is 0.4590\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Run call was cancelled\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-46ec2d6ca70c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mcoord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-46ec2d6ca70c>\u001b[0m in \u001b[0;36mbackward\u001b[1;34m()\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;31m#                 xs, ys = mnist.train.next_batch(BATCH_SIZE)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                 \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb_xs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb_ys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;31m#                 reshaped_xs = np.reshape(xs, [BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerged\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "STEPS = 100  # 根据所有样本的代数停止\n",
    "INTERATIONS = 10000  # 根据迭代次数停止训练\n",
    "BATCH_SIZE = 512\n",
    "LEARNING_RATE_BASE = 0.003\n",
    "LEARNING_RATE_DECAY = 0.99\n",
    "MOVING_AVERAGE_DECAY = 0.99\n",
    "MODEL_SAVE_PATH = './Lenet5/model/'\n",
    "MODEL_NAME = 'Lenet-5_model'\n",
    "\n",
    "if not os.path.exists(MODEL_SAVE_PATH): os.mkdir(MODEL_SAVE_PATH)\n",
    "\n",
    "# mnist = input_data.read_data_sets(\"G:/MNIST_data/\", one_hot = True)\n",
    "def backward():\n",
    "    tf.reset_default_graph()\n",
    "    X, Y = create_placeholder()\n",
    "    y = forward(X, True)\n",
    "    \n",
    "    global_step = tf.Variable(0, trainable = False, name = 'train_step')\n",
    "    learning_rate = tf.train.exponential_decay(  # 学习率指数衰减，\n",
    "        LEARNING_RATE_BASE, \n",
    "        global_step, \n",
    "        60000 / BATCH_SIZE, \n",
    "        LEARNING_RATE_DECAY, \n",
    "        staircase = True)\n",
    "    tf.summary.scalar('learning_rate', learning_rate)\n",
    "    \n",
    "    with tf.name_scope('optimizer'):\n",
    "        with tf.name_scope('loss'):\n",
    "            mean_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y, labels = Y))  \n",
    "            # tf.nn.sparse_softmax_cross_entropy_with_logits(logits = y, labels = tf.argmax(Y, 1))\n",
    "            tf.add_to_collection('losses', mean_loss)  # loss = mean_loss + tf.add_n(tf.get_collection('losses'))\n",
    "            loss = tf.add_n(tf.get_collection('losses'))\n",
    "            tf.summary.scalar('mean_loss', mean_loss)\n",
    "            tf.summary.scalar('loss_l2', loss)\n",
    "        train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step = global_step)\n",
    "        ema = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)  # 滑动平均\n",
    "        ema_op = ema.apply(tf.trainable_variables())\n",
    "        with tf.control_dependencies([train_step, ema_op]):  # 训练时同步更新滑动平均值\n",
    "            train_op = tf.no_op(name = 'train')\n",
    "        \n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(Y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = 'accuracy')\n",
    "        tf.summary.scalar('train', accuracy)\n",
    "        \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True  # 允许显存增长，（显存不足）\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    b_xs, b_ys = get_tf(BATCH_SIZE, Train=True)\n",
    "    with tf.Session(config = config) as sess:\n",
    "        merged = tf.summary.merge_all()\n",
    "        writer = tf.summary.FileWriter(MODEL_SAVE_PATH, sess.graph)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        coord=tf.train.Coordinator()    \n",
    "        threads= tf.train.start_queue_runners(coord=coord)\n",
    "        \n",
    "        ckpt = tf.train.get_checkpoint_state(MODEL_SAVE_PATH)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        \n",
    "#         step = sess.run(global_step)\n",
    "        n_batch = int(60000 / BATCH_SIZE)\n",
    "        for epoch in range(STEPS): # range(step, STEPS)\n",
    "            epoch_loss = 0\n",
    "            epoch_acc = 0\n",
    "            for i in range(n_batch):\n",
    "#                 xs, ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "                xs, ys = sess.run([b_xs,b_ys])\n",
    "#                 reshaped_xs = np.reshape(xs, [BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS])\n",
    "                _, loss_value, acc, step, summary = sess.run([train_op, loss, accuracy, global_step, merged], feed_dict = {X:xs, Y:ys})\n",
    "#                 print(step)\n",
    "                epoch_loss += loss_value/n_batch\n",
    "                epoch_acc += acc/n_batch\n",
    "                writer.add_summary(summary, step)\n",
    "                print('INFO: After %d training iteration(s), loss is %.5f, batch_train accuracy is %.4f' % (step, loss_value, acc))\n",
    "                if step % 100 == 0:\n",
    "                    saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME+ '.ckpt'), global_step = global_step)\n",
    "                    print('%s-%d.ckpt saved!' % (MODEL_NAME, step))\n",
    "                if step >= INTERATIONS: return\n",
    "#                     print('INFO: After %d training iteration(s), loss is %.5f, batch_train accuracy is %.4f' % (step, loss_value, acc))\n",
    "#             if epoch % 10 == 0:\n",
    "            print('After %d training epoch(s)(X%d), loss is %.5f, train accuracy is %.4f' % (epoch+1, n_batch, epoch_loss, epoch_acc))\n",
    "            saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME+'.ckpt-{:d}x{:d}').format(epoch+1, n_batch))\n",
    "            print('%s-%dx%d saved!' % (MODEL_NAME, epoch+1, n_batch))\n",
    "#             sess.run(global_step.assign(epoch))\n",
    "#             print('%s-%d saved!' % (MODEL_NAME, epoch))\n",
    "#             if step >= INTERATIONS: break\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "    \n",
    "backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估准确率\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "TEST_INTERVAL_SECS = 5  # 间隔\n",
    "\n",
    "def evaluation(mnist_image, mnist_label, num_examples):  # mnist.test.images, minst.test.num_examples\n",
    "    with tf.Graph().as_default() as g:\n",
    "        X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "        Y = tf.placeholder(tf.float32, [None, 10])\n",
    "        y = forward(X, False, None)\n",
    "        \n",
    "        em = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY)  # 滑动平均\n",
    "        em_restore = em.variables_to_restore()\n",
    "        saver = tf.train.Saver(em_restore)\n",
    "        \n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(Y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "#         while True:\n",
    "        with tf.Session() as sess:\n",
    "            ckpt = tf.train.get_checkpoint_state(MODEL_SAVE_PATH)\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "                steps = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "                reshape_x = np.reshape(mnist_image, [num_examples, 28, 28, 1])\n",
    "                acc_ = sess.run(accuracy, feed_dict = {X:reshape_x, Y:mnist_label})\n",
    "                print('After %s training step(s), evaluation accuracy is %.4f' % (steps, acc_))\n",
    "            else:\n",
    "                print('No checkpoint file found!')\n",
    "                return\n",
    "#             time.sleep(TEST_INTERVAL_SECS)\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"G:/MNIST_data/\", one_hot = True)\n",
    "evaluation(mnist.test.images, mnist.test.labels, mnist.test.num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
